name: Build and deploy Python project to Azure Function App - Projet-Analyse-Sentiment

on:
  push:
    branches:
      - main
  workflow_dispatch:

env: # Workflow-level environment variables, accessible in all jobs
  PYTHON_VERSION: '3.10'
  AZURE_FUNCTIONAPP_ROOT_FOLDER: 'API' # Base path for function app code
  MLFLOW_REGISTERED_MODEL_NAME: 'MODEL_ADVANCED'
  MLFLOW_TRACKING_URI_RELATIVE: 'Modélisation/mlruns' 
  ARTIFACT_ZIP_NAME: 'python-app.zip'

jobs:
  build:
    runs-on: ubuntu-latest
    permissions: 
      contents: read
    env: # Job-level environment variables for the 'build' job
        # We reconstruct the path or use github.workspace directly
        # AZURE_FUNCTIONAPP_ROOT_FOLDER_JOB: 'api' # If you wanted to override or specify differently at job level
        FUNCTION_APP_MODEL_DIR_ABSOLUTE: ${{ github.workspace }}/API/model # Construct full path directly
                                                                      # Using the known value 'api' from workflow env

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 

      - name: Setup Python version
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }} # Workflow env is fine here

      - name: Install MLflow and Function App dependencies
        run: |
          python -m pip install --upgrade pip
          pip install mlflow 
          pip install -r ${{ env.AZURE_FUNCTIONAPP_ROOT_FOLDER }}/requirements.txt # Workflow env is fine here
      
      - name: Create target model directory in Function App folder
        # Use the job-level 'FUNCTION_APP_MODEL_DIR_ABSOLUTE' which was constructed correctly
        run: mkdir -p ${{ env.FUNCTION_APP_MODEL_DIR_ABSOLUTE }}

      - name: Download latest registered model and tokenizer from MLflow
        run: |
          # ... (setup of env vars for Python script as before) ...
          
          python -c """
          import mlflow
          import shutil
          import os
          import re # For regex

          # ... (retrieve env vars model_name, target_model_dir, mlflow_tracking_uri_for_script) ...
          # ... (check if env vars are set) ...

          mlflow.set_tracking_uri(mlflow_tracking_uri_for_script)
          print(f'Python script: MLflow tracking URI effectively set to: {mlflow.get_tracking_uri()}')
          
          client = mlflow.tracking.MlflowClient()
          
          try:
              print(f"Fetching latest versions for model: {model_name} using client with URI: {client._tracking_client.tracking_uri if hasattr(client, '_tracking_client') else 'N/A'}")
              latest_version_info = client.get_latest_versions(model_name, stages=['None'])
              # ... (handle if no versions found) ...

              latest_model_version_obj = latest_version_info[0]
              run_id_from_registry = latest_model_version_obj.run_id 
              source_uri_from_registry = latest_model_version_obj.source

              print(f'Latest version for {model_name}: Version {latest_model_version_obj.version}, Run ID from registry: {run_id_from_registry}')
              print(f'DEBUG: Source URI from registry: {source_uri_from_registry}')

              # --- Attempt to directly copy files if download_artifacts fails due to source URI ---
              # This assumes MLFLOW_TRACKING_URI_RELATIVE points to 'Modélisation/mlruns'
              # And github.workspace is the root of the repo on the runner.

              # Try to parse experiment_id and run_id from the source_uri_from_registry
              # Regex to find .../mlruns/<experiment_id>/<run_id>/...
              # This regex assumes 'mlruns' is in the path, followed by exp_id, then run_id
              match = re.search(r'mlruns/([^/]+)/([^/]+)/artifacts', source_uri_from_registry)
              experiment_id_from_source = None
              run_id_from_source = None

              if match:
                  experiment_id_from_source = match.group(1)
                  run_id_from_source = match.group(2)
                  print(f'Parsed from source URI: Experiment ID = {experiment_id_from_source}, Run ID = {run_id_from_source}')
                  if run_id_from_source != run_id_from_registry:
                      print(f'WARNING: Run ID from registry ({run_id_from_registry}) differs from parsed Run ID ({run_id_from_source}). Using registry one.')
              else:
                  print(f'Could not parse experiment ID and Run ID from source URI: {source_uri_from_registry}')
                  # Fallback or error - for now, let's try to proceed assuming run_id_from_registry is primary
                  # If we can't get experiment_id, constructing the full path is hard without listing experiments.
                  # However, the structure of mlruns usually uses experiment_id as a directory name.
                  # Let's assume the experiment_id is needed for the path.
                  # This part becomes tricky if we can't reliably get the experiment_id.

              # Construct the base path to the checked-out mlruns on the runner
              # GITHUB_WORKSPACE_FOR_PYTHON is passed from shell
              github_workspace = os.environ.get('GITHUB_WORKSPACE_FOR_PYTHON')
              mlflow_tracking_uri_relative_for_python = os.environ.get('MLFLOW_TRACKING_URI_RELATIVE_FOR_PYTHON')
              
              if not github_workspace or not mlflow_tracking_uri_relative_for_python:
                  print('Error: GITHUB_WORKSPACE_FOR_PYTHON or MLFLOW_TRACKING_URI_RELATIVE_FOR_PYTHON not set for Python script.')
                  exit(1)

              # Path to the root of the mlruns directory on the runner
              base_mlruns_path_on_runner = os.path.join(github_workspace, mlflow_tracking_uri_relative_for_python)
              print(f'Base mlruns path on runner: {base_mlruns_path_on_runner}')

              # If we couldn't parse experiment_id, this approach is stuck.
              # For now, let's assume we MUST have experiment_id_from_source if we go this manual route.
              # A more robust way would be client.get_run(run_id_from_registry).info.experiment_id
              try:
                  run_info = client.get_run(run_id_from_registry)
                  experiment_id_from_run_info = run_info.info.experiment_id
                  print(f'Got Experiment ID from run_info: {experiment_id_from_run_info}')
              except Exception as e_get_run:
                  print(f'Could not get run_info for {run_id_from_registry}: {e_get_run}')
                  print('Proceeding with parsed experiment_id if available, otherwise this manual copy will likely fail.')
                  experiment_id_from_run_info = experiment_id_from_source # Fallback to parsed

              if not experiment_id_from_run_info:
                  print('CRITICAL: Cannot determine experiment ID. Manual file copy will fail.')
                  # Attempt MLflow download one last time before failing completely
                  try:
                      print(f'Attempting mlflow.artifacts.download_artifacts one last time for model...')
                      mlflow.artifacts.download_artifacts(run_id=run_id_from_registry, artifact_path='model/data/model.keras', dst_path=target_model_dir)
                      # ... (move logic) ...
                      print(f'Attempting mlflow.artifacts.download_artifacts one last time for tokenizer...')
                      mlflow.artifacts.download_artifacts(run_id=run_id_from_registry, artifact_path='tokenizer/keras_tokenizer.pkl', dst_path=target_model_dir)
                      # ... (move logic) ...
                      print('MLflow download succeeded on last attempt.')
                  except Exception as e_mlflow_dl:
                      print(f'Final attempt with mlflow.artifacts.download_artifacts also failed: {e_mlflow_dl}')
                      print('Exiting due to inability to fetch artifacts.')
                      exit(1)
              else:
                  # --- Manual File Copy Logic ---
                  runner_model_artifact_src_path = os.path.join(
                      base_mlruns_path_on_runner,
                      experiment_id_from_run_info, # Use experiment ID from run_info
                      run_id_from_registry,        # Use run ID from registry
                      'artifacts',
                      'model', 'data', 'model.keras' # Relative path within artifacts
                  )
                  runner_tokenizer_artifact_src_path = os.path.join(
                      base_mlruns_path_on_runner,
                      experiment_id_from_run_info,
                      run_id_from_registry,
                      'artifacts',
                      'tokenizer', 'keras_tokenizer.pkl'
                  )

                  final_model_path_in_target = os.path.join(target_model_dir, 'model.keras')
                  final_tokenizer_path_in_target = os.path.join(target_model_dir, 'keras_tokenizer.pkl')

                  print(f'Manually copying model from (runner path): {runner_model_artifact_src_path} to {final_model_path_in_target}')
                  if os.path.exists(runner_model_artifact_src_path):
                      shutil.copy(runner_model_artifact_src_path, final_model_path_in_target)
                  else:
                      print(f'ERROR: Source model file not found on runner: {runner_model_artifact_src_path}')
                      exit(1)
                  
                  print(f'Manually copying tokenizer from (runner path): {runner_tokenizer_artifact_src_path} to {final_tokenizer_path_in_target}')
                  if os.path.exists(runner_tokenizer_artifact_src_path):
                      shutil.copy(runner_tokenizer_artifact_src_path, final_tokenizer_path_in_target)
                  else:
                      print(f'ERROR: Source tokenizer file not found on runner: {runner_tokenizer_artifact_src_path}')
                      exit(1)
                  
                  print('Manual file copy completed.')
              # --- End Manual File Copy Logic ---


              print(f'Model and tokenizer should be in {target_model_dir}')
              print('Final contents of target model directory:')
              os.system(f'ls -lR {target_model_dir}')

          except Exception as e:
              print(f'ERROR in Python script: {e}')
              import traceback
              traceback.print_exc()
              exit(1)
          """
        env: 
          MLFLOW_REGISTERED_MODEL_NAME_SCRIPT: ${{ env.MLFLOW_REGISTERED_MODEL_NAME }}
          FUNCTION_APP_MODEL_DIR_ABSOLUTE_SCRIPT: ${{ env.FUNCTION_APP_MODEL_DIR_ABSOLUTE }}
          MLFLOW_TRACKING_URI_FOR_PYTHON_SCRIPT: "file://${{ github.workspace }}/${{ env.MLFLOW_TRACKING_URI_RELATIVE }}"
          GITHUB_WORKSPACE_FOR_PYTHON: ${{ github.workspace }} # Pass workspace to Python
          MLFLOW_TRACKING_URI_RELATIVE_FOR_PYTHON: ${{ env.MLFLOW_TRACKING_URI_RELATIVE }} # Pass relative path

      - name: Zip artifact for deployment (Function App folder contents)
        run: |
          echo "Current directory before zipping: $(pwd)"
          echo "Zipping contents of ${{ env.AZURE_FUNCTIONAPP_ROOT_FOLDER }} into ../${{ env.ARTIFACT_ZIP_NAME }}"
          cd ${{ env.AZURE_FUNCTIONAPP_ROOT_FOLDER }} # Uses workflow env
          zip -r ../${{ env.ARTIFACT_ZIP_NAME }} . -x "*venv/*" -x "*.git/*" -x "*__pycache__/*" # Uses workflow env
          cd .. 
          echo "Zip file created at: $(pwd)/${{ env.ARTIFACT_ZIP_NAME }}" # Uses workflow env
          ls -l ${{ env.ARTIFACT_ZIP_NAME }} # Uses workflow env


      - name: Upload artifact for deployment job
        uses: actions/upload-artifact@v4
        with:
          name: python-app-artifact
          path: ${{ env.ARTIFACT_ZIP_NAME }} # Uses workflow env

  deploy:
    runs-on: ubuntu-latest
    needs: build
    environment:
      name: 'Production'
      url: ${{ steps.deploy-to-function.outputs.webapp-url }}
    
    steps:
      - name: Download artifact from build job
        uses: actions/download-artifact@v4
        with:
          name: python-app-artifact

      - name: List files after download
        run: ls -lR

      - name: 'Deploy to Azure Functions'
        uses: Azure/functions-action@v1
        id: deploy-to-function
        with:
          app-name: 'Projet-Analyse-Sentiment'
          slot-name: 'Production'
          package: ${{ env.ARTIFACT_ZIP_NAME }} # Uses workflow env
          publish-profile: ${{ secrets.AZUREAPPSERVICE_PUBLISHPROFILE_18963F46B19E49D5A57355029EB94F04 }}