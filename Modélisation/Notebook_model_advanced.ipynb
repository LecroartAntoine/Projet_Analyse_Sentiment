{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Projet 7 : Réalisez une analyse de sentiments grâce au Deep Learning](#toc0_)\n",
    "# <a id='toc2_'></a>[Modèle sur mesure avancé](#toc0_)\n",
    "\n",
    "[Lien OpenClassroom](https://openclassrooms.com/fr/paths/795/projects/1516/1578-mission)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0a5b7",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Projet 7 : Réalisez une analyse de sentiments grâce au Deep Learning](#toc1_)    \n",
    "- [Modèle sur mesure simple](#toc2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb27ab",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc2_1_'></a>[Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df1d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding,\n",
    "    LSTM,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Bidirectional,\n",
    "    Input,\n",
    "    SpatialDropout1D,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import mlflow\n",
    "import mlflow.tensorflow  # Essential for autologging\n",
    "import pickle  # For saving the tokenizer\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c25120",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc2_2_'></a>[Chargement des données](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f48e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully:\n",
      "Train samples: 1114106\n",
      "Validation samples: 238737\n",
      "Test samples: 238738\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_PATH = \"./train_data.csv\"\n",
    "VAL_DATA_PATH = \"./validation_data.csv\"\n",
    "TEST_DATA_PATH = \"./test_data.csv\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "val_df = pd.read_csv(VAL_DATA_PATH)\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "# Handle potential NaN values in 'cleaned_text' that might result from preprocessing\n",
    "train_df[\"cleaned_text\"].fillna(\"\", inplace=True)\n",
    "val_df[\"cleaned_text\"].fillna(\"\", inplace=True)\n",
    "test_df[\"cleaned_text\"].fillna(\"\", inplace=True)\n",
    "\n",
    "\n",
    "X_train = train_df[\"cleaned_text\"]\n",
    "y_train = train_df[\"sentiment\"].replace({\"negative\": 0, \"positive\": 1}).astype(int)\n",
    "X_val = val_df[\"cleaned_text\"]\n",
    "y_val = val_df[\"sentiment\"].replace({\"negative\": 0, \"positive\": 1}).astype(int)\n",
    "X_test = test_df[\"cleaned_text\"]\n",
    "y_test = test_df[\"sentiment\"].replace({\"negative\": 0, \"positive\": 1}).astype(int)\n",
    "\n",
    "print(\"Data loaded successfully:\")\n",
    "print(f\"Train samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c7d5e",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Préparation pour Deep Leanring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c617c5c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Création d'un Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1754d1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual vocabulary size used: 200\n",
      "Shape of padded training sequences: (1114106, 20)\n",
      "Shape of padded validation sequences: (238737, 20)\n",
      "Shape of padded test sequences: (238738, 20)\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 200\n",
    "MAX_SEQUENCE_LENGTH = 20\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=VOCAB_SIZE, oov_token=\"<OOV>\"\n",
    ")  # OOV token for out-of-vocabulary words\n",
    "\n",
    "# Fit the tokenizer ONLY on the training data\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text data to sequences of integers\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X_train_pad = pad_sequences(\n",
    "    X_train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "X_val_pad = pad_sequences(\n",
    "    X_val_seq, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "X_test_pad = pad_sequences(\n",
    "    X_test_seq, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "\n",
    "# Vocabulary size for the embedding layer (add 1 for the padding token 0)\n",
    "# Use min to handle cases where actual vocab is smaller than VOCAB_SIZE\n",
    "actual_vocab_size = min(VOCAB_SIZE, len(tokenizer.word_index) + 1)\n",
    "print(f\"Actual vocabulary size used: {actual_vocab_size}\")\n",
    "print(f\"Shape of padded training sequences: {X_train_pad.shape}\")\n",
    "print(f\"Shape of padded validation sequences: {X_val_pad.shape}\")\n",
    "print(f\"Shape of padded test sequences: {X_test_pad.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb24600",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Sauvegarde du Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8433580",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"keras_tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04334440",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### MLFlow Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f742b283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow experiment set to: 'Tweet Sentiment Analysis - Advanced DL'\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"Tweet Sentiment Analysis - Advanced DL\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "print(f\"MLflow experiment set to: '{EXPERIMENT_NAME}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89208305",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Experiment 1: LSTM avec GloVe Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d2432",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Chargement de GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "142412d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors in ./glove.6B.300d.txt.\n",
      "Creating embedding matrix...\n",
      "Converted 198 words (1 misses)\n",
      "Shape of embedding matrix: (200, 300)\n"
     ]
    }
   ],
   "source": [
    "GLOVE_PATH = \"./glove.6B.300d.txt\"\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "embeddings_index = {}\n",
    "try:\n",
    "    with open(GLOVE_PATH, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "            embeddings_index[word] = coefs\n",
    "    print(f\"Found {len(embeddings_index)} word vectors in {GLOVE_PATH}.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: GloVe file not found at {GLOVE_PATH}\")\n",
    "    print(\"Skipping GloVe experiment.\")\n",
    "    embeddings_index = None  # Ensure variable exists but is None\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred loading GloVe file: {e}\")\n",
    "    embeddings_index = None\n",
    "\n",
    "embedding_matrix = None\n",
    "if embeddings_index:\n",
    "    print(\"Creating embedding matrix...\")\n",
    "    # Initialize matrix with zeros\n",
    "    embedding_matrix = np.zeros((actual_vocab_size, EMBEDDING_DIM))\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    # Populate the matrix with GloVe vectors for words in our tokenizer's vocabulary\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i >= actual_vocab_size:  # Skip words beyond our vocab size limit\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "    print(f\"Converted {hits} words ({misses} misses)\")\n",
    "    print(f\"Shape of embedding matrix: {embedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd908a97",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    max_length,\n",
    "    lstm_units,\n",
    "    dropout_rate,\n",
    "    spatial_dropout_rate,\n",
    "    learning_rate,\n",
    "    embedding_matrix=None,\n",
    "    is_embedding_trainable=False,\n",
    "):\n",
    "    \"\"\"Builds a Keras LSTM model, OPTIMIZED for speed.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(max_length,)))\n",
    "\n",
    "    model.add(\n",
    "        Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            weights=[embedding_matrix],\n",
    "            input_length=max_length,\n",
    "            trainable=is_embedding_trainable,  # Explicitly False for GloVe\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(SpatialDropout1D(spatial_dropout_rate))\n",
    "    model.add(LSTM(lstm_units, dropout=dropout_rate, recurrent_dropout=dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    print(\"\\nOptimized Model Summary:\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a070458",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Entrainement du modèle avec MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456ea880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting MLflow Run for: LSTM_GloVe_Embeddings ---\n",
      "MLflow Run ID (GloVe): 0c17b15490fb4c54ba166550369a5e49\n",
      "Using pre-trained embedding matrix (non-trainable).\n",
      "\n",
      "Optimized Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">60,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │        \u001b[38;5;34m60,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m42,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,657</span> (401.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m102,657\u001b[0m (401.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,657</span> (166.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,657\u001b[0m (166.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,000</span> (234.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m60,000\u001b[0m (234.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/16 15:34:15 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LSTM model with GloVe embeddings...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6779 - loss: 0.5900"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 42ms/step - accuracy: 0.6779 - loss: 0.5900 - val_accuracy: 0.7120 - val_loss: 0.5491\n",
      "Epoch 2/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7073 - loss: 0.5555"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 36ms/step - accuracy: 0.7073 - loss: 0.5555 - val_accuracy: 0.7140 - val_loss: 0.5447\n",
      "Epoch 3/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7111 - loss: 0.5490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 36ms/step - accuracy: 0.7111 - loss: 0.5490 - val_accuracy: 0.7147 - val_loss: 0.5425\n",
      "Epoch 4/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7122 - loss: 0.5470"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 36ms/step - accuracy: 0.7122 - loss: 0.5470 - val_accuracy: 0.7151 - val_loss: 0.5416\n",
      "Epoch 5/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7135 - loss: 0.5448"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 36ms/step - accuracy: 0.7135 - loss: 0.5448 - val_accuracy: 0.7163 - val_loss: 0.5398\n",
      "Epoch 6/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7135 - loss: 0.5439"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 36ms/step - accuracy: 0.7135 - loss: 0.5439 - val_accuracy: 0.7173 - val_loss: 0.5395\n",
      "Epoch 7/10\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7139 - loss: 0.5425"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 36ms/step - accuracy: 0.7139 - loss: 0.5425 - val_accuracy: 0.7170 - val_loss: 0.5387\n",
      "Epoch 8/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7151 - loss: 0.5417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 36ms/step - accuracy: 0.7151 - loss: 0.5417 - val_accuracy: 0.7173 - val_loss: 0.5385\n",
      "Epoch 9/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7141 - loss: 0.5412"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 36ms/step - accuracy: 0.7141 - loss: 0.5412 - val_accuracy: 0.7180 - val_loss: 0.5378\n",
      "Epoch 10/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7153 - loss: 0.5408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 37ms/step - accuracy: 0.7153 - loss: 0.5408 - val_accuracy: 0.7182 - val_loss: 0.5374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
      "GloVe Model Training Finished.\n",
      "Tokenizer logged as artifact to MLflow run 0c17b15490fb4c54ba166550369a5e49.\n",
      "--- MLflow Run 0c17b15490fb4c54ba166550369a5e49 finished ---\n"
     ]
    }
   ],
   "source": [
    "LSTM_UNITS = 32\n",
    "DROPOUT_RATE = 0.2\n",
    "SPATIAL_DROPOUT_RATE = 0.2\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 512\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "TOKENIZER_ARTIFACT_PATH = \"tokenizer\"\n",
    "MODEL_ARTIFACT_PATH = \"model\"\n",
    "\n",
    "run_name_glove = \"LSTM_GloVe_Embeddings\"\n",
    "print(f\"\\n--- Starting MLflow Run for: {run_name_glove} ---\")\n",
    "\n",
    "\n",
    "mlflow.tensorflow.autolog(\n",
    "    log_models=True, disable=False, registered_model_name=None\n",
    ")  # Disable registration via autolog for now\n",
    "\n",
    "with mlflow.start_run(run_name=run_name_glove) as run_glove:\n",
    "    run_id_glove = run_glove.info.run_id\n",
    "    print(f\"MLflow Run ID (GloVe): {run_id_glove}\")\n",
    "\n",
    "    # --- Log additional parameters manually (autolog might miss some) ---\n",
    "    mlflow.log_param(\"embedding_type\", \"GloVe (Not Trainable)\")\n",
    "    mlflow.log_param(\"vocab_size\", actual_vocab_size)\n",
    "    mlflow.log_param(\"max_sequence_length\", MAX_SEQUENCE_LENGTH)\n",
    "    mlflow.log_param(\"embedding_dim\", EMBEDDING_DIM)\n",
    "    mlflow.log_param(\"lstm_units\", LSTM_UNITS)\n",
    "    mlflow.log_param(\"dropout_rate\", DROPOUT_RATE)\n",
    "    mlflow.log_param(\"spatial_dropout_rate\", SPATIAL_DROPOUT_RATE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"architecture\", \"Input-Embedding-SpatialDropout-BiLSTM-Dense\")\n",
    "\n",
    "    # --- Build the model ---\n",
    "    model_glove = build_lstm_model(\n",
    "        vocab_size=actual_vocab_size,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        max_length=MAX_SEQUENCE_LENGTH,\n",
    "        lstm_units=LSTM_UNITS,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        spatial_dropout_rate=SPATIAL_DROPOUT_RATE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        embedding_matrix=embedding_matrix,\n",
    "    )\n",
    "\n",
    "    # --- Callbacks ---\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=2, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # --- Train the model ---\n",
    "    print(\"\\nTraining LSTM model with GloVe embeddings...\")\n",
    "    history_glove = model_glove.fit(\n",
    "        X_train_pad,\n",
    "        y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1,\n",
    "    )\n",
    "    print(\"GloVe Model Training Finished.\")\n",
    "\n",
    "    if os.path.exists(\"keras_tokenizer.pkl\"):\n",
    "        mlflow.log_artifact(\n",
    "            \"keras_tokenizer.pkl\", artifact_path=TOKENIZER_ARTIFACT_PATH\n",
    "        )\n",
    "        print(f\"Tokenizer logged as artifact to MLflow run {run_id_glove}.\")\n",
    "    else:\n",
    "        print(\n",
    "            \"Warning: Tokenizer file keras_tokenizer.pkl not found, could not log artifact.\"\n",
    "        )\n",
    "\n",
    "    print(f\"--- MLflow Run {run_id_glove} finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a0a9d",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Experiment 2: LSTM avec GloVe Embeddings (Entrainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01781e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting MLflow Run for: LSTM_Trainable_Embeddings ---\n",
      "MLflow Run ID (Trainable): b72ca14fe64c4a549306aebe1ba4641c\n",
      "\n",
      "Optimized Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">60,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │        \u001b[38;5;34m60,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m42,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,657</span> (401.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m102,657\u001b[0m (401.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,657</span> (401.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m102,657\u001b[0m (401.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/16 15:55:16 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LSTM model with Trainable embeddings...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6866 - loss: 0.5778"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 42ms/step - accuracy: 0.6866 - loss: 0.5778 - val_accuracy: 0.7142 - val_loss: 0.5419\n",
      "Epoch 2/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7129 - loss: 0.5419"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 41ms/step - accuracy: 0.7129 - loss: 0.5419 - val_accuracy: 0.7167 - val_loss: 0.5371\n",
      "Epoch 3/10\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7160 - loss: 0.5371"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 42ms/step - accuracy: 0.7160 - loss: 0.5371 - val_accuracy: 0.7182 - val_loss: 0.5347\n",
      "Epoch 4/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7177 - loss: 0.5348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 41ms/step - accuracy: 0.7177 - loss: 0.5348 - val_accuracy: 0.7192 - val_loss: 0.5333\n",
      "Epoch 5/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7185 - loss: 0.5326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 41ms/step - accuracy: 0.7185 - loss: 0.5326 - val_accuracy: 0.7199 - val_loss: 0.5329\n",
      "Epoch 6/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7192 - loss: 0.5321"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 41ms/step - accuracy: 0.7192 - loss: 0.5321 - val_accuracy: 0.7204 - val_loss: 0.5321\n",
      "Epoch 7/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7194 - loss: 0.5320"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 42ms/step - accuracy: 0.7194 - loss: 0.5320 - val_accuracy: 0.7208 - val_loss: 0.5317\n",
      "Epoch 8/10\n",
      "\u001b[1m2175/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7212 - loss: 0.5297"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 41ms/step - accuracy: 0.7212 - loss: 0.5297 - val_accuracy: 0.7202 - val_loss: 0.5312\n",
      "Epoch 9/10\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7216 - loss: 0.5290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 42ms/step - accuracy: 0.7216 - loss: 0.5290 - val_accuracy: 0.7208 - val_loss: 0.5308\n",
      "Epoch 10/10\n",
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7214 - loss: 0.5292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2176/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 45ms/step - accuracy: 0.7214 - loss: 0.5292 - val_accuracy: 0.7210 - val_loss: 0.5307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
      "Trainable Model Training Finished.\n",
      "Tokenizer logged as artifact to MLflow run 0c17b15490fb4c54ba166550369a5e49.\n",
      "--- MLflow Run 0c17b15490fb4c54ba166550369a5e49 finished ---\n"
     ]
    }
   ],
   "source": [
    "run_name_trainable = \"LSTM_Trainable_Embeddings\"\n",
    "print(f\"\\n--- Starting MLflow Run for: {run_name_trainable} ---\")\n",
    "\n",
    "# Re-enable autologging for the new run if it was disabled, ensure clean state\n",
    "mlflow.tensorflow.autolog(log_models=True, disable=False, registered_model_name=None)\n",
    "\n",
    "with mlflow.start_run(run_name=run_name_trainable) as run_trainable:\n",
    "    run_id_trainable = run_trainable.info.run_id\n",
    "    print(f\"MLflow Run ID (Trainable): {run_id_trainable}\")\n",
    "\n",
    "    # --- Log additional parameters manually ---\n",
    "    mlflow.log_param(\"embedding_type\", \"Trainable\")\n",
    "    mlflow.log_param(\"vocab_size\", actual_vocab_size)\n",
    "    mlflow.log_param(\"max_sequence_length\", MAX_SEQUENCE_LENGTH)\n",
    "    mlflow.log_param(\n",
    "        \"embedding_dim\", EMBEDDING_DIM\n",
    "    )  # Can be different from GloVe dim if desired\n",
    "    mlflow.log_param(\"lstm_units\", LSTM_UNITS)\n",
    "    mlflow.log_param(\"dropout_rate\", DROPOUT_RATE)\n",
    "    mlflow.log_param(\"spatial_dropout_rate\", SPATIAL_DROPOUT_RATE)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"architecture\", \"Input-Embedding-SpatialDropout-BiLSTM-Dense\")\n",
    "\n",
    "    # --- Build the model ---\n",
    "    model_trainable = build_lstm_model(\n",
    "        vocab_size=actual_vocab_size,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        max_length=MAX_SEQUENCE_LENGTH,\n",
    "        lstm_units=LSTM_UNITS,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        spatial_dropout_rate=SPATIAL_DROPOUT_RATE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        embedding_matrix=embedding_matrix,\n",
    "        is_embedding_trainable=True,\n",
    "    )\n",
    "\n",
    "    # --- Callbacks ---\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # --- Train the model ---\n",
    "    print(\"\\nTraining LSTM model with Trainable embeddings...\")\n",
    "    history_trainable = model_trainable.fit(\n",
    "        X_train_pad,\n",
    "        y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1,\n",
    "    )\n",
    "    print(\"Trainable Model Training Finished.\")\n",
    "\n",
    "    # --- Manually log the tokenizer artifact ---\n",
    "    if os.path.exists(\"keras_tokenizer.pkl\"):\n",
    "        mlflow.log_artifact(\n",
    "            \"keras_tokenizer.pkl\", artifact_path=TOKENIZER_ARTIFACT_PATH\n",
    "        )\n",
    "        print(f\"Tokenizer logged as artifact to MLflow run {run_id_glove}.\")\n",
    "    else:\n",
    "        print(\n",
    "            \"Warning: Tokenizer file keras_tokenizer.pkl not found, could not log artifact.\"\n",
    "        )\n",
    "\n",
    "    print(f\"--- MLflow Run {run_id_glove} finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd664f5",
   "metadata": {},
   "source": [
    "## Evaluation et Selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
