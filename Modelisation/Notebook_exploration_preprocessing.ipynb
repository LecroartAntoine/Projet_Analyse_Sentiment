{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f62266f",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Projet 7 : Réalisez une analyse de sentiments grâce au Deep Learning](#toc0_)\n",
    "# <a id='toc2_'></a>[Exploration & Preprocessing](#toc0_)\n",
    "\n",
    "[Lien OpenClassroom](https://openclassrooms.com/fr/paths/795/projects/1516/1578-mission)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942bd0c",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Projet 7 : Réalisez une analyse de sentiments grâce au Deep Learning](#toc1_)    \n",
    "- [Exploration & Preprocessing](#toc2_)    \n",
    "  - [Imports](#toc2_1_)    \n",
    "  - [Analyse Exploratoire](#toc2_2_)    \n",
    "    - [Chargement du jeu de données](#toc2_2_1_)    \n",
    "    - [Analyse sommaire](#toc2_2_2_)    \n",
    "    - [Suppression des colonnes inutiles](#toc2_2_3_)    \n",
    "    - [Analyse colonne '?'](#toc2_2_4_)    \n",
    "    - [Modification de la colonne label](#toc2_2_5_)    \n",
    "    - [Analyse Statistique Simple](#toc2_2_6_)    \n",
    "      - [Distribution des labels](#toc2_2_6_1_)    \n",
    "      - [Longueur des Tweets](#toc2_2_6_2_)    \n",
    "      - [Comptage des mots](#toc2_2_6_3_)    \n",
    "    - [Analyse Statistique Avancée](#toc2_2_7_)    \n",
    "      - [Netoyage sommaire pour analyse](#toc2_2_7_1_)    \n",
    "      - [Mots les plus utilisés](#toc2_2_7_2_)    \n",
    "      - [Bi-gramme](#toc2_2_7_3_)    \n",
    "      - [Ponctuation](#toc2_2_7_4_)    \n",
    "  - [ Préprocessing](#toc2_3_)    \n",
    "    - [Préparation du texte](#toc2_3_1_)    \n",
    "    - [Suppression des Tweets devenuent vide](#toc2_3_2_)    \n",
    "    - [Affichage comparatif](#toc2_3_3_)    \n",
    "    - [Découpage du jeu de données final](#toc2_3_4_)    \n",
    "    - [Sauvegarde du jeu de données](#toc2_3_5_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e96ac",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc2_1_'></a>[Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d89d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sweetviz as sv\n",
    "import skimpy as sk\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import contractions\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "TEMPLATE = \"plotly_dark\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc88a53",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc2_2_'></a>[Analyse Exploratoire](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6bed4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_2_1_'></a>[Chargement du jeu de données](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"./raw_dataset.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    encoding_errors=\"ignore\",\n",
    "    names=[\"?\", \"user_id\", \"datetime\", \"??\", \"username\", \"message\"],\n",
    ")\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec1f36c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_2_2_'></a>[Analyse sommaire](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1470a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher une analyse descriptive rapide avec skimpy\n",
    "sk.skim(df)\n",
    "\n",
    "# Créer un rapport d'analyse avec sweetviz\n",
    "report = sv.analyze(df)\n",
    "# Enregistrer le rapport sweetviz en HTML\n",
    "report.show_html(\"sweetviz_report.html\")\n",
    "# Afficher le rapport sweetviz dans le notebook (peut ne pas fonctionner dans tous les environnements)\n",
    "report.show_notebook()\n",
    "\n",
    "# Afficher des informations sur le DataFrame (types de données, nombre de valeurs non nulles, etc.)\n",
    "df.info()\n",
    "\n",
    "# Afficher le nombre de colonnes pour chaque type de données\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e93a7c3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_2_3_'></a>[Suppression des colonnes inutiles](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87461c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"??\", \"datetime\", \"username\", \"user_id\"], axis=1, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c74d2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_2_4_'></a>[Analyse colonne '?'](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages où la colonne inconue = 0 :\")\n",
    "for message in df[df[\"?\"] == 0][\"message\"].head(10):\n",
    "    print(\"\\t\" + message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c4539",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages où la colonne inconue = 4 :\")\n",
    "for message in df[df[\"?\"] == 4][\"message\"].head(10):\n",
    "    print(\"\\t\" + message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b05572",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc2_2_5_'></a>[Modification de la colonne label](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda3b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"?\"]\n",
    "\n",
    "df[\"label\"].replace({4: \"positive\", 0: \"negative\"}, inplace=True)\n",
    "\n",
    "df.drop(\"?\", axis=1, inplace=True)\n",
    "\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a387ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_2_6_'></a>[Analyse Statistique Simple](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebf5e5",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_6_1_'></a>[Distribution des labels](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2851ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df[\"label\"].value_counts()\n",
    "fig_pie = px.pie(\n",
    "    label_counts,\n",
    "    values=label_counts.values,\n",
    "    names=label_counts.index,\n",
    "    title=\"Distribution des sentiments\",\n",
    "    hole=0.3,\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig_pie.update_traces(textposition=\"inside\", textinfo=\"percent+label\")\n",
    "fig_pie.show()\n",
    "\n",
    "fig_bar_dist = px.bar(\n",
    "    label_counts,\n",
    "    x=label_counts.index,\n",
    "    y=label_counts.values,\n",
    "    title=\"Distribution des sentiments\",\n",
    "    labels={\"x\": \"Sentiment\", \"y\": \"Quantité de Tweets\"},\n",
    "    color=label_counts.index,\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    "    text_auto=True,\n",
    ")\n",
    "fig_bar_dist.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae7fc63",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_6_2_'></a>[Longueur des Tweets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweet_length\"] = df[\"message\"].str.len()\n",
    "\n",
    "# Histogram of tweet lengths\n",
    "fig_hist_len = px.histogram(\n",
    "    df,\n",
    "    x=\"tweet_length\",\n",
    "    title=\"Distribution de la longueur des Tweets\",\n",
    "    marginal=\"box\",  # Add box plot on top\n",
    "    labels={\"tweet_length\": \"Tweet Length (Characters)\"},\n",
    ")\n",
    "fig_hist_len.show()\n",
    "\n",
    "fig_box_len = px.box(\n",
    "    df,\n",
    "    x=\"label\",\n",
    "    y=\"tweet_length\",\n",
    "    color=\"label\",\n",
    "    title=\"Distribution de la longueur des Tweets par Sentiment\",\n",
    "    labels={\"label\": \"Sentiment\", \"tweet_length\": \"Longueur du Tweet (Characters)\"},\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig_box_len.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6354640",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_6_3_'></a>[Comptage des mots](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaeeebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"word_count\"] = df[\"message\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# Histogram of word counts\n",
    "fig_hist_wc = px.histogram(\n",
    "    df,\n",
    "    x=\"word_count\",\n",
    "    title=\"Distribution de la quantité de mots pour chaque Tweet\",\n",
    "    marginal=\"box\",\n",
    "    labels={\"word_count\": \"Word Count\"},\n",
    ")\n",
    "fig_hist_wc.show()\n",
    "\n",
    "# Compare word counts by sentiment\n",
    "fig_box_wc = px.box(\n",
    "    df,\n",
    "    x=\"label\",\n",
    "    y=\"word_count\",\n",
    "    color=\"label\",\n",
    "    title=\"Quantité de mots par Sentiment\",\n",
    "    labels={\"label\": \"Sentiment\", \"word_count\": \"Comptage Mot\"},\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    ")\n",
    "fig_box_wc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5305b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_2_7_'></a>[Analyse Statistique Avancée](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18adea53",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_7_1_'></a>[Custommisation des stop words](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words = [word for word in stop_words if not word.endswith(\"n't\") and word != \"not\"]\n",
    "\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a2b9c0",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_7_1_'></a>[Netoyage sommaire pour analyse](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f88beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(\n",
    "        r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE\n",
    "    )  # Remove URLs\n",
    "    text = re.sub(r\"\\@\\w+|\\#\", \"\", text)  # Remove mentions and hashtags\n",
    "    text = text.translate(\n",
    "        str.maketrans(\"\", \"\", string.punctuation)\n",
    "    )  # Remove punctuation\n",
    "    text = re.sub(r\"\\d+\", \"\", text)  # Remove numbers\n",
    "\n",
    "    # DECONTRACTED\n",
    "    text = re.sub(r\"\\'t\", \"not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"cleaned_message\"] = df[\"message\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6bb547",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_7_2_'></a>[Mots les plus utilisés](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb6ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(corpus, n=20):\n",
    "    tokens = nltk.word_tokenize(\" \".join(corpus))\n",
    "    tokens = [word for word in tokens if word not in stop_words and word.isalpha()]\n",
    "    count = Counter(tokens)\n",
    "    most_common = count.most_common(n)\n",
    "    df_common = pd.DataFrame(most_common, columns=[\"word\", \"count\"])\n",
    "    return df_common\n",
    "\n",
    "\n",
    "top_words_overall = get_top_words(df[\"cleaned_message\"], n=10)\n",
    "fig_bar_overall = px.bar(\n",
    "    top_words_overall,\n",
    "    x=\"count\",\n",
    "    y=\"word\",\n",
    "    orientation=\"h\",\n",
    "    title=\"Top 10 des mots les plus utilisés\",\n",
    "    labels={\"count\": \"Fréquence\", \"word\": \"Mot\"},\n",
    "    color=\"count\",\n",
    "    color_continuous_scale=px.colors.sequential.Viridis,\n",
    ")\n",
    "fig_bar_overall.update_layout(\n",
    "    yaxis={\"categoryorder\": \"total ascending\"}, template=TEMPLATE\n",
    ")\n",
    "fig_bar_overall.show()\n",
    "\n",
    "# Top Words for Positive Tweets\n",
    "top_words_pos = get_top_words(df[df[\"label\"] == \"positive\"][\"cleaned_message\"], n=10)\n",
    "fig_bar_pos = px.bar(\n",
    "    top_words_pos,\n",
    "    x=\"count\",\n",
    "    y=\"word\",\n",
    "    orientation=\"h\",\n",
    "    title=\"Top 10 des mots les plus utilisés pour les Tweets positifs\",\n",
    "    labels={\"count\": \"Fréquence\", \"word\": \"Mot\"},\n",
    "    color=\"count\",\n",
    "    color_continuous_scale=px.colors.sequential.Greens,\n",
    ")\n",
    "fig_bar_pos.update_layout(yaxis={\"categoryorder\": \"total ascending\"}, template=TEMPLATE)\n",
    "fig_bar_pos.show()\n",
    "\n",
    "# Top Words for Negative Tweets\n",
    "top_words_neg = get_top_words(df[df[\"label\"] == \"negative\"][\"cleaned_message\"], n=10)\n",
    "fig_bar_neg = px.bar(\n",
    "    top_words_neg,\n",
    "    x=\"count\",\n",
    "    y=\"word\",\n",
    "    orientation=\"h\",\n",
    "    title=\"Top 10 des mots les plus utilisés pour les Tweets negatifs\",\n",
    "    labels={\"count\": \"Fréquence\", \"word\": \"Mot\"},\n",
    "    color=\"count\",\n",
    "    color_continuous_scale=px.colors.sequential.Reds,\n",
    ")\n",
    "fig_bar_neg.update_layout(yaxis={\"categoryorder\": \"total ascending\"}, template=TEMPLATE)\n",
    "fig_bar_neg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55db4ac",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_7_3_'></a>[Bi-gramme](https://fr.wikipedia.org/wiki/N-gramme) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_ngrams(corpus, n=20, ngram_range=(2, 2)):\n",
    "    tokens = nltk.word_tokenize(\" \".join(corpus))\n",
    "    tokens = [word for word in tokens if word not in stop_words and word.isalpha()]\n",
    "    n_grams = ngrams(tokens, ngram_range[0])  # Adjust for different n-grams\n",
    "    count = Counter(n_grams)\n",
    "    most_common = count.most_common(n)\n",
    "    # Format ngrams for display\n",
    "    most_common_formatted = [(\" \".join(ngram), freq) for ngram, freq in most_common]\n",
    "    df_common = pd.DataFrame(most_common_formatted, columns=[\"ngram\", \"count\"])\n",
    "    return df_common\n",
    "\n",
    "\n",
    "# Top Bigrams for Positive Tweets\n",
    "top_bigrams_overall = get_top_ngrams(df[\"cleaned_message\"], n=10, ngram_range=(2, 2))\n",
    "fig_bar_bi_pos = px.bar(\n",
    "    top_bigrams_overall,\n",
    "    x=\"count\",\n",
    "    y=\"ngram\",\n",
    "    orientation=\"h\",\n",
    "    title=\"Top 10 des Bigrammes pour tous les Tweets\",\n",
    "    labels={\"count\": \"Fréquence\", \"ngram\": \"Bigram\"},\n",
    "    color=\"count\",\n",
    "    color_continuous_scale=px.colors.sequential.Greens,\n",
    ")\n",
    "fig_bar_bi_pos.update_layout(\n",
    "    yaxis={\"categoryorder\": \"total ascending\"}, template=TEMPLATE\n",
    ")\n",
    "fig_bar_bi_pos.show()\n",
    "\n",
    "\n",
    "# Top Bigrams for Positive Tweets\n",
    "top_bigrams_pos = get_top_ngrams(\n",
    "    df[df[\"label\"] == \"positive\"][\"cleaned_message\"], n=10, ngram_range=(2, 2)\n",
    ")\n",
    "fig_bar_bi_pos = px.bar(\n",
    "    top_bigrams_pos,\n",
    "    x=\"count\",\n",
    "    y=\"ngram\",\n",
    "    orientation=\"h\",\n",
    "    title=\"Top 10 des Bigrammes pour les Tweets positifs\",\n",
    "    labels={\"count\": \"Fréquence\", \"ngram\": \"Bigram\"},\n",
    "    color=\"count\",\n",
    "    color_continuous_scale=px.colors.sequential.Greens,\n",
    ")\n",
    "fig_bar_bi_pos.update_layout(\n",
    "    yaxis={\"categoryorder\": \"total ascending\"}, template=TEMPLATE\n",
    ")\n",
    "fig_bar_bi_pos.show()\n",
    "\n",
    "# Top Bigrams for Negative Tweets\n",
    "top_bigrams_neg = get_top_ngrams(\n",
    "    df[df[\"label\"] == \"negative\"][\"cleaned_message\"], n=10, ngram_range=(2, 2)\n",
    ")\n",
    "fig_bar_bi_neg = px.bar(\n",
    "    top_bigrams_neg,\n",
    "    x=\"count\",\n",
    "    y=\"ngram\",\n",
    "    orientation=\"h\",\n",
    "    title=\"Top 10 des Bigrammes pour les Tweets négatifs\",\n",
    "    labels={\"count\": \"Fréquence\", \"ngram\": \"Bigram\"},\n",
    "    color=\"count\",\n",
    "    color_continuous_scale=px.colors.sequential.Reds,\n",
    ")\n",
    "fig_bar_bi_neg.update_layout(\n",
    "    yaxis={\"categoryorder\": \"total ascending\"}, template=TEMPLATE\n",
    ")\n",
    "fig_bar_bi_neg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275b2fa5",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_7_4_'></a>[Ponctuation](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"exclamation_count\"] = df[\"message\"].str.count(\"!\")\n",
    "df[\"question_mark_count\"] = df[\"message\"].str.count(\"\\?\")\n",
    "\n",
    "# Compare counts by sentiment using box plots\n",
    "fig_box_punct = make_subplots(\n",
    "    rows=1, cols=2, subplot_titles=(\"Points d'exclamation\", \"Points d'intérogation\")\n",
    ")\n",
    "\n",
    "fig_box_punct.add_trace(\n",
    "    go.Box(\n",
    "        y=df[df[\"label\"] == \"positive\"][\"exclamation_count\"],\n",
    "        name=\"Positif\",\n",
    "        marker_color=\"lightgreen\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig_box_punct.add_trace(\n",
    "    go.Box(\n",
    "        y=df[df[\"label\"] == \"negative\"][\"exclamation_count\"],\n",
    "        name=\"Negatif\",\n",
    "        marker_color=\"lightcoral\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig_box_punct.add_trace(\n",
    "    go.Box(\n",
    "        y=df[df[\"label\"] == \"positive\"][\"question_mark_count\"],\n",
    "        name=\"Positif\",\n",
    "        marker_color=\"lightgreen\",\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "fig_box_punct.add_trace(\n",
    "    go.Box(\n",
    "        y=df[df[\"label\"] == \"negative\"][\"question_mark_count\"],\n",
    "        name=\"Negatif\",\n",
    "        marker_color=\"lightcoral\",\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig_box_punct.update_layout(\n",
    "    title_text=\"Utilisation de la ponctuation par type de Tweet\",\n",
    "    height=400,\n",
    "    template=TEMPLATE,\n",
    ")\n",
    "fig_box_punct.update_yaxes(title_text=\"Nombre par Tweet\", row=1, col=1)\n",
    "fig_box_punct.update_yaxes(title_text=\"Nombre par Tweet\", row=1, col=2)\n",
    "fig_box_punct.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32b9ac",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc2_3_'></a>[ Préprocessing](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5540113f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_3_1_'></a>[Préparation du texte](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692557a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    \"\"\"Applies cleaning steps to a single text string.\"\"\"\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "\n",
    "        return \"\"  # Return empty string for non-string inputs\n",
    "\n",
    "\n",
    "    # 1. Convert to lowercase\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "\n",
    "    # 2. Expand contractions\n",
    "\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "\n",
    "    # 3. Remove URLs\n",
    "\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "\n",
    "\n",
    "    # 4. Remove mentions (@username)\n",
    "\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "\n",
    "\n",
    "    # 5. Remove hashtags (#topic) - removes the '#' symbol and the word\n",
    "\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "\n",
    "\n",
    "    # 6. Remove numbers\n",
    "\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "\n",
    "    # 7. Remove special characters and punctuation (keeping spaces)\n",
    "\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "\n",
    "    # DECONTRACTED\n",
    "    text = re.sub(r\"\\'t\", \"not\", text)\n",
    "\n",
    "\n",
    "    # 8. Tokenization\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "\n",
    "    # 9. Remove stop words and lemmatize\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for word in tokens:\n",
    "\n",
    "        if len(word) > 1 and word not in stop_words:\n",
    "\n",
    "            lemma = lemmatizer.lemmatize(word)\n",
    "\n",
    "            cleaned_tokens.append(lemma)\n",
    "\n",
    "\n",
    "    # 10. Join tokens back into a single string\n",
    "\n",
    "    cleaned_text = \" \".join(cleaned_tokens)\n",
    "\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "\n",
    "df[\"cleaned_tweet\"] = df[\"message\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1510c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "### <a id='toc2_3_2_'></a>[Suppression des Tweets devenuent vide](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_after_clean = df[df[\"cleaned_tweet\"] == \"\"].shape[0]\n",
    "print(\n",
    "    f\"\\nNumber of tweets resulting in empty strings after cleaning: {empty_after_clean}\"\n",
    ")\n",
    "\n",
    "if empty_after_clean > 0:\n",
    "    df = df[df[\"cleaned_tweet\"] != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf72f67a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_3_3_'></a>[Affichage comparatif](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190eaa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExample Preprocessing:\")\n",
    "for line in df.sample(10).itertuples():\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Original:  {line[1]}\")\n",
    "    print(f\"Cleaned:   {line[8]}\")\n",
    "    print(f\"Sentiment: {line[2]}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fedab55",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_3_4_'></a>[Découpage du jeu de données final](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb88149",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"cleaned_tweet\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Split ratio\n",
    "TEST_SIZE = 0.15\n",
    "VALIDATION_SIZE = 0.15  # Relative to the original size\n",
    "\n",
    "# First split: Train vs. (Validation + Test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=(VALIDATION_SIZE + TEST_SIZE),\n",
    "    random_state=42,  # for reproducibility\n",
    "    stratify=y,  # Ensure distribution is similar across splits\n",
    ")\n",
    "\n",
    "# Calculate split size for validation relative to the 'temp' set\n",
    "val_split_ratio = VALIDATION_SIZE / (VALIDATION_SIZE + TEST_SIZE)\n",
    "\n",
    "# Second split: Validation vs. Test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=(1 - val_split_ratio),  # Test size is the remainder\n",
    "    random_state=42,  # for reproducibility\n",
    "    stratify=y_temp,  # Ensure distribution is similar across splits\n",
    ")\n",
    "\n",
    "print(\"Data Splitting Complete:\")\n",
    "print(f\"Training set shape:   X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Validation set shape: X={X_val.shape}, y={y_val.shape}\")\n",
    "print(f\"Test set shape:       X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "# Verify stratification (optional)\n",
    "print(\"\\nSentiment distribution in splits:\")\n",
    "print(\"Train:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Validation:\\n\", y_val.value_counts(normalize=True))\n",
    "print(\"Test:\\n\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f28f4c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_3_5_'></a>[Sauvegarde du jeu de données](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for easy saving\n",
    "train_df = pd.DataFrame({\"cleaned_text\": X_train, \"sentiment\": y_train})\n",
    "val_df = pd.DataFrame({\"cleaned_text\": X_val, \"sentiment\": y_val})\n",
    "test_df = pd.DataFrame({\"cleaned_text\": X_test, \"sentiment\": y_test})\n",
    "\n",
    "# Save to CSV\n",
    "train_df.to_csv(\"train_data.csv\", index=False)\n",
    "val_df.to_csv(\"validation_data.csv\", index=False)\n",
    "test_df.to_csv(\"test_data.csv\", index=False)\n",
    "print(\"\\nSplit data saved to train_data.csv, validation_data.csv, test_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
