{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e372de6d",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Projet 7 : Réalisez une analyse de sentiments grâce au Deep Learning](#toc0_)\n",
    "# <a id='toc2_'></a>[Modèle sur mesure simple](#toc0_)\n",
    "\n",
    "[Lien OpenClassroom](https://openclassrooms.com/fr/paths/795/projects/1516/1578-mission)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f238ea",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Projet 7 : Réalisez une analyse de sentiments grâce au Deep Learning](#toc1_)    \n",
    "- [Modèle sur mesure simple](#toc2_)    \n",
    "  - [Imports](#toc2_1_)    \n",
    "  - [Chargement des données](#toc2_2_)    \n",
    "    - [Chargement du fichier csv](#toc2_2_1_)    \n",
    "    - [Découpage du jeu de données](#toc2_2_2_)    \n",
    "  - [Préparation et tests](#toc2_3_)    \n",
    "    - [Fonctions de préprocessing](#toc2_3_1_)    \n",
    "    - [ Test des approches de preprocessing](#toc2_3_2_)    \n",
    "    - [Setup MLFlow](#toc2_3_3_)    \n",
    "  - [Extraction des features, entrainement du modèle et logging MLFlow](#toc2_4_)    \n",
    "  - [Évaluation du modèle](#toc2_5_)    \n",
    "    - [Évaluation sur les données de test](#toc2_5_1_)    \n",
    "    - [Comparaison avec un modèle naif](#toc2_5_2_)    \n",
    "    - [Enregistrement du model](#toc2_5_3_)    \n",
    "  - [Dashboard MLFlow](#toc2_6_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb84c77",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc2_1_'></a>[Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df1d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import contractions\n",
    "\n",
    "try:\n",
    "    stopwords.words(\"english\")\n",
    "except LookupError:\n",
    "    nltk.download(\"stopwords\")\n",
    "try:\n",
    "    word_tokenize(\"test\")\n",
    "except LookupError:\n",
    "    nltk.download(\"punkt\")\n",
    "try:\n",
    "    WordNetLemmatizer().lemmatize(\"cats\")\n",
    "except LookupError:\n",
    "    nltk.download(\"wordnet\")\n",
    "    nltk.download(\"omw-1.4\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fcaf2a",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc2_2_'></a>[Chargement des données](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bc0df4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_2_1_'></a>[Chargement du fichier csv](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f48e53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tweet",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "27d5f1ef-8617-4497-9fe5-dd5b17af6181",
       "rows": [
        [
         "1183467",
         "fruit loops with marshmellows    lmfao cunt spell.",
         "1"
        ],
        [
         "575121",
         "well life sucks! i have to work next sat so no truller trip for me ",
         "0"
        ],
        [
         "951487",
         "I recieved an unexpected text! How exciting!  The forcast is looking sunny in Neil world! Shame back in reality its raining! bleuch!",
         "1"
        ],
        [
         "138012",
         "Planning for a vacation..but no friends to accompany ",
         "0"
        ],
        [
         "371219",
         "The curious case of benjamen button was so sad ",
         "0"
        ],
        [
         "1252690",
         "At Ruby Tuesday's with Crystal and Sarah. Fun times! ",
         "1"
        ],
        [
         "911893",
         "@sharonhayes..where is the song? ",
         "1"
        ],
        [
         "1414677",
         "And now Uncle Howard's singing... up for 5 Na Hoku awards Tuesday for his debut album!  ",
         "1"
        ],
        [
         "442429",
         "@Janetita @Danime, That would work, except I don't have the money to go over there. ",
         "0"
        ],
        [
         "1148483",
         "@tracecyruss i love the legit wear shirt! ",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1183467</th>\n",
       "      <td>fruit loops with marshmellows    lmfao cunt sp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575121</th>\n",
       "      <td>well life sucks! i have to work next sat so no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951487</th>\n",
       "      <td>I recieved an unexpected text! How exciting!  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138012</th>\n",
       "      <td>Planning for a vacation..but no friends to acc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371219</th>\n",
       "      <td>The curious case of benjamen button was so sad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252690</th>\n",
       "      <td>At Ruby Tuesday's with Crystal and Sarah. Fun ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911893</th>\n",
       "      <td>@sharonhayes..where is the song?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414677</th>\n",
       "      <td>And now Uncle Howard's singing... up for 5 Na ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442429</th>\n",
       "      <td>@Janetita @Danime, That would work, except I d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148483</th>\n",
       "      <td>@tracecyruss i love the legit wear shirt!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  label\n",
       "1183467  fruit loops with marshmellows    lmfao cunt sp...      1\n",
       "575121   well life sucks! i have to work next sat so no...      0\n",
       "951487   I recieved an unexpected text! How exciting!  ...      1\n",
       "138012   Planning for a vacation..but no friends to acc...      0\n",
       "371219     The curious case of benjamen button was so sad       0\n",
       "1252690  At Ruby Tuesday's with Crystal and Sarah. Fun ...      1\n",
       "911893                   @sharonhayes..where is the song?       1\n",
       "1414677  And now Uncle Howard's singing... up for 5 Na ...      1\n",
       "442429   @Janetita @Danime, That would work, except I d...      0\n",
       "1148483         @tracecyruss i love the legit wear shirt!       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"./data.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b0c02",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_2_2_'></a>[Découpage du jeu de données](#toc0_)\n",
    "\n",
    "Cette cellule est dédiée à la division du jeu de données en ensembles d'entraînement, de validation et de test. Elle utilise une approche de double train_test_split pour assurer une répartition stratifiée des labels dans chaque sous-ensemble, garantissant ainsi que la distribution des sentiments est similaire à celle du jeu de données original. Les proportions sont définies pour un ensemble d'entraînement de 70%, un ensemble de validation de 15% et un ensemble de test de 15%. Enfin, les formes des ensembles et la distribution des sentiments au sein de chacun sont affichées pour vérification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36197ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Division des données terminée :\n",
      "Taille de l'ensemble d'entraînement :   X=(1120000,), y=(1120000,)\n",
      "Taille de l'ensemble de validation : X=(240000,), y=(240000,)\n",
      "Taille de l'ensemble de test :       X=(240000,), y=(240000,)\n",
      "\n",
      "Distribution des sentiments dans les ensembles :\n",
      "Entraînement :\n",
      " label\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Validation :\n",
      " label\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Test :\n",
      " label\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Définir les features (X) et les labels (y)\n",
    "X = df[\"tweet\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Définir les tailles des ensembles de test et de validation\n",
    "TEST_SIZE = 0.15\n",
    "VALIDATION_SIZE = 0.15\n",
    "\n",
    "# Première division : entraînement vs. (validation + test)\n",
    "# L'ensemble temporaire contient les données pour la validation et le test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=(VALIDATION_SIZE + TEST_SIZE),  # Taille combinée pour temp\n",
    "    random_state=42,  # Pour la reproductibilité\n",
    "    stratify=y,  # Pour maintenir la distribution des labels\n",
    ")\n",
    "\n",
    "# Calculer la proportion de l'ensemble de validation par rapport à l'ensemble temporaire\n",
    "val_split_ratio = VALIDATION_SIZE / (VALIDATION_SIZE + TEST_SIZE)\n",
    "\n",
    "# Deuxième division : validation vs. test à partir de l'ensemble temporaire\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=(1 - val_split_ratio),  # La partie restante sera pour le test\n",
    "    random_state=42,\n",
    "    stratify=y_temp,  # Maintenir la distribution des labels dans le sous-ensemble\n",
    ")\n",
    "\n",
    "# Afficher les formes des ensembles après la division\n",
    "print(\"Division des données terminée :\")\n",
    "print(f\"Taille de l'ensemble d'entraînement :   X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Taille de l'ensemble de validation : X={X_val.shape}, y={y_val.shape}\")\n",
    "print(f\"Taille de l'ensemble de test :       X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "# Afficher la distribution des sentiments dans chaque ensemble\n",
    "print(\"\\nDistribution des sentiments dans les ensembles :\")\n",
    "print(\"Entraînement :\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Validation :\\n\", y_val.value_counts(normalize=True))\n",
    "print(\"Test :\\n\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e70fd21",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc2_3_'></a>[Préparation et tests](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d4d4b",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc2_3_1_'></a>[Fonctions de préprocessing](#toc0_)\n",
    "\n",
    "Cette cellule définit trois fonctions de prétraitement du texte, chacune offrant un niveau de nettoyage différent pour la colonne tweet.\n",
    "- preprocess_full : Effectue un nettoyage complet incluant la conversion en minuscules, l'expansion des contractions, la suppression des URLs, mentions, hashtags, nombres et caractères spéciaux. Elle tokenise ensuite le texte, supprime les stop_words et applique la lemmatisation.\n",
    "\n",
    "- preprocess_no_stopwords : Similaire à preprocess_full, mais elle conserve les stop_words, se concentrant sur la normalisation des contractions, la suppression des éléments non textuels et la lemmatisation.\n",
    "\n",
    "- preprocess_none : Cette fonction ne réalise aucun prétraitement, retournant le texte original si c'est une chaîne, ou une chaîne vide sinon.\n",
    "\n",
    "Ces fonctions sont conçues pour être utilisées ultérieurement afin d'expérimenter l'impact de différentes stratégies de prétraitement sur les performances des modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94bfe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_full(text):\n",
    "    \"\"\"\n",
    "    Applique toutes les étapes de nettoyage du texte, y compris la suppression des stop words.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Convertir le texte en minuscules\n",
    "    text = text.lower()\n",
    "    # Étendre les contractions (ex: \"don't\" -> \"do not\")\n",
    "    text = contractions.fix(text)\n",
    "    # Supprimer les URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    # Supprimer les mentions (@user)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    # Supprimer les hashtags (#tag)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    # Supprimer les nombres\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    # Supprimer les caractères spéciaux et la ponctuation (ne garder que les lettres et espaces)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "\n",
    "    # Tokeniser le texte en mots\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = []\n",
    "    for word in tokens:\n",
    "        # Supprimer les stop words et les mots d'une seule lettre, puis lemmatiser\n",
    "        if len(word) > 1 and word not in stop_words:\n",
    "            lemma = lemmatizer.lemmatize(word)\n",
    "            cleaned_tokens.append(lemma)\n",
    "    # Rejoindre les jetons nettoyés en une seule chaîne\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "\n",
    "def preprocess_no_stopwords(text):\n",
    "    \"\"\"\n",
    "    Applique toutes les étapes de nettoyage du texte, SAUF la suppression des stop words.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = contractions.fix(text)\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = []\n",
    "    for word in tokens:\n",
    "        # Lemmatiser sans supprimer les stop words\n",
    "        if len(word) > 1:\n",
    "            lemma = lemmatizer.lemmatize(word)\n",
    "            cleaned_tokens.append(lemma)\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "\n",
    "def preprocess_none(text):\n",
    "    \"\"\"\n",
    "    N'applique aucun prétraitement, retourne le texte tel quel (ou une chaîne vide si ce n'est pas une chaîne).\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8266bc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_3_2_'></a>[ Test des approches de preprocessing](#toc0_)\n",
    "\n",
    "Cette cellule met en place un processus d'évaluation comparative pour un modèle de régression logistique, en testant l'impact de différentes stratégies de prétraitement du texte.\n",
    "\n",
    "train_eval_logistic_regression : Cette fonction encapsule le pipeline d'entraînement et d'évaluation. Elle utilise TfidfVectorizer pour convertir le texte prétraité en caractéristiques numériques (fréquences TF-IDF des mots, limitées à 10 000 caractéristiques les plus fréquentes), puis entraîne un modèle LogisticRegression. Elle retourne l'exactitude (accuracy) et le score F1 (métriques de performance du modèle).\n",
    "\n",
    "Boucle de benchmarking : La cellule itère sur les trois configurations de prétraitement définies précédemment (preprocess_none, preprocess_no_stopwords, preprocess_full). Pour chaque configuration :\n",
    "\n",
    "- Les ensembles X_train et X_test sont prétraités en utilisant la fonction pp_function correspondante.\n",
    "\n",
    "- Le modèle de régression logistique est entraîné et évalué avec ces données prétraitées.\n",
    "\n",
    "- Les résultats (modèle utilisé, type de prétraitement, accuracy, F1-Score) sont stockés dans la liste results_log.\n",
    "\n",
    "L'objectif est d'identifier quelle stratégie de prétraitement optimise les performances du modèle de régression logistique pour la tâche d'analyse de sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c8a12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BENCHMARKING AVEC PRÉTRAITEMENT : Sans Prétraitement ---\n",
      "Entraînement de la Régression Logistique...\n",
      "Régression Logistique - Accuracy: 0.7935, F1-Score: 0.7961\n",
      "\n",
      "--- BENCHMARKING AVEC PRÉTRAITEMENT : Tout Sauf Mots Vides ---\n",
      "Entraînement de la Régression Logistique...\n",
      "Régression Logistique - Accuracy: 0.7921, F1-Score: 0.7946\n",
      "\n",
      "--- BENCHMARKING AVEC PRÉTRAITEMENT : Tout Prétraitement ---\n",
      "Entraînement de la Régression Logistique...\n",
      "Régression Logistique - Accuracy: 0.7684, F1-Score: 0.7735\n"
     ]
    }
   ],
   "source": [
    "def train_eval_logistic_regression(\n",
    "    X_train_processed, y_train, X_test_processed, y_test\n",
    "):\n",
    "    \"\"\"\n",
    "    Entraîne et évalue un modèle de régression logistique avec TF-IDF.\n",
    "\n",
    "    Args:\n",
    "        X_train_processed (list): Textes d'entraînement prétraités.\n",
    "        y_train (pd.Series): Labels d'entraînement.\n",
    "        X_test_processed (list): Textes de test prétraités.\n",
    "        y_test (pd.Series): Labels de test.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (accuracy, f1_score)\n",
    "    \"\"\"\n",
    "    print(\"Entraînement de la Régression Logistique...\")\n",
    "    # Initialiser et entraîner un vectorisateur TF-IDF sur les données d'entraînement\n",
    "    vectorizer = TfidfVectorizer(max_features=10000)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train_processed)\n",
    "    # Transformer les données de test avec le vectorisateur entraîné\n",
    "    X_test_tfidf = vectorizer.transform(X_test_processed)\n",
    "\n",
    "    # Initialiser et entraîner le modèle de régression logistique\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    # Faire des prédictions sur l'ensemble de test\n",
    "    predictions = model.predict(X_test_tfidf)\n",
    "    # Calculer l'exactitude (accuracy)\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    # Calculer le score F1 (pour les classes binaires)\n",
    "    f1 = f1_score(y_test, predictions, average=\"binary\")\n",
    "    return acc, f1\n",
    "\n",
    "\n",
    "# Définir les différentes configurations de prétraitement à tester\n",
    "preprocessing_configs = {\n",
    "    \"Sans Prétraitement\": preprocess_none,\n",
    "    \"Tout Sauf stop words\": preprocess_no_stopwords,\n",
    "    \"Tout Prétraitement\": preprocess_full,\n",
    "}\n",
    "\n",
    "results_log = []  # Liste pour stocker les résultats\n",
    "\n",
    "# Boucler sur chaque configuration de prétraitement\n",
    "for pp_name, pp_function in preprocessing_configs.items():\n",
    "    print(f\"\\n--- BENCHMARKING AVEC PRÉTRAITEMENT : {pp_name} ---\")\n",
    "\n",
    "    # Appliquer la fonction de prétraitement aux ensembles d'entraînement et de test\n",
    "    current_X_train = [pp_function(text) for text in X_train]\n",
    "    current_X_test = [pp_function(text) for text in X_test]\n",
    "\n",
    "    # Utiliser les labels non modifiés\n",
    "    current_y_train = y_train\n",
    "    current_y_test = y_test\n",
    "\n",
    "    # --- Régression Logistique ---\n",
    "    # Entraîner et évaluer le modèle avec les données prétraitées\n",
    "    acc, f1 = train_eval_logistic_regression(\n",
    "        current_X_train, current_y_train, current_X_test, current_y_test\n",
    "    )\n",
    "    # Enregistrer les résultats\n",
    "    results_log.append(\n",
    "        {\n",
    "            \"Modèle\": \"LogisticRegression+TFIDF\",\n",
    "            \"Prétraitement\": pp_name,\n",
    "            \"Accuracy\": acc,\n",
    "            \"F1-Score\": f1,\n",
    "        }\n",
    "    )\n",
    "    print(f\"Régression Logistique - Accuracy: {acc:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8668af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_3_3_'></a>[Setup MLFlow](#toc0_)\n",
    "\n",
    "Cette cellule initialise et configure l'environnement MLflow pour le suivi des expériences. Elle définit un nom d'expérience (EXPERIMENT_NAME) et tente de la définir comme l'expérience MLflow active. Si l'expérience n'existe pas, elle est créée. L'objectif est de centraliser et de versionner les résultats et les artefacts des différents runs du modèle. De plus, elle définit une constante pour le nom de fichier qui sera utilisé pour sauvegarder le vectoriseur TF-IDF, un composant clé du pipeline de traitement du texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6945cef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation de l'expérience existante 'Tweet Sentiment Analysis - Simple Models' avec ID : 897408299388468996\n"
     ]
    }
   ],
   "source": [
    "# Nom de l'expérience MLflow\n",
    "EXPERIMENT_NAME = \"Tweet Sentiment Analysis - Simple Models\"\n",
    "# Définir l'expérience MLflow courante\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# Récupérer les détails de l'expérience courante (ou en créer une si elle n'existe pas)\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if experiment is None:\n",
    "        experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "        print(f\"Nouvelle expérience créée avec ID : {experiment_id}\")\n",
    "    else:\n",
    "        experiment_id = experiment.experiment_id\n",
    "        print(\n",
    "            f\"Utilisation de l'expérience existante '{EXPERIMENT_NAME}' avec ID : {experiment_id}\"\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la configuration de l'expérience MLflow : {e}\")\n",
    "    raise\n",
    "\n",
    "# Nom de fichier pour sauvegarder le vectoriseur TF-IDF\n",
    "VECTORIZER_FILENAME = \"tfidf_vectorizer_simple.joblib\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b06ec",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc2_4_'></a>[Extraction des features, entrainement du modèle et logging MLFlow](#toc0_)\n",
    "\n",
    "Cette cellule encapsule l'intégralité du processus d'entraînement et d'évaluation d'un modèle de régression logistique pour l'analyse de sentiment, tout en utilisant MLflow pour le suivi et la gestion de l'expérience.\n",
    "\n",
    "Initialisation MLflow : Une nouvelle exécution MLflow est démarrée sous le nom spécifié.\n",
    "\n",
    "Paramètres : Les hyperparamètres clés du vectoriseur TF-IDF (comme max_features et ngram_range) et du modèle de régression logistique (comme C, solver, max_iter, class_weight) sont définis et enregistrés en tant que paramètres MLflow.\n",
    "\n",
    "Extraction de Caractéristiques (TF-IDF) : Un TfidfVectorizer est entraîné sur l'ensemble d'entraînement et utilisé pour transformer les ensembles d'entraînement, de validation et de test en représentations numériques. Le vectoriseur entraîné est ensuite sauvegardé localement et enregistré en tant qu'artefact MLflow pour une réutilisation future.\n",
    "\n",
    "Entraînement du Modèle : Le modèle LogisticRegression est initialisé avec les paramètres définis et entraîné sur les données d'entraînement transformées.\n",
    "\n",
    "Évaluation sur l'Ensemble de Validation : Le modèle est évalué sur l'ensemble de validation en utilisant des métriques clés comme l'accuracy, la précision, le rappel et le score F1. Toutes ces métriques sont enregistrées dans MLflow.\n",
    "\n",
    "Enregistrement du Modèle et Rapports : Le modèle entraîné est enregistré en tant qu'artefact MLflow. De plus, un rapport de classification détaillé est généré et également enregistré en tant qu'artefact pour une analyse approfondie.\n",
    "\n",
    "L'objectif principal de cette cellule est de documenter de manière exhaustive chaque aspect de cette exécution modèle au sein de MLflow, permettant une traçabilité, une reproductibilité et une comparaison facile avec d'autres expériences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d226bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Début de l'exécution MLflow : LogisticRegression_TFIDF\n",
      "ID de l'exécution MLflow : d43f58cea498442dbbb0035cdc96cc82\n",
      "Enregistrement des paramètres...\n",
      "Entraînement du vectoriseur TF-IDF...\n",
      "TF-IDF - Forme des données d'entraînement transformées : (1120000, 10000)\n",
      "TF-IDF - Forme des données de validation transformées : (240000, 10000)\n",
      "TF-IDF - Forme des données de test transformées : (240000, 10000)\n",
      "Vectoriseur sauvegardé localement dans tfidf_vectorizer_simple.joblib\n",
      "Vectoriseur enregistré comme artefact MLflow.\n",
      "Entraînement du modèle de Régression Logistique...\n",
      "Entraînement du modèle terminé.\n",
      "Évaluation sur l'ensemble de validation...\n",
      "Enregistrement des métriques de validation...\n",
      "Validation Accuracy : 0.8051\n",
      "Validation Précision : 0.7981\n",
      "Validation Rappel : 0.8169\n",
      "Validation F1-Score : 0.8074\n",
      "Enregistrement du modèle entraîné...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/17 19:22:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle enregistré avec succès.\n",
      "\n",
      "Exécution MLflow d43f58cea498442dbbb0035cdc96cc82 terminée.\n"
     ]
    }
   ],
   "source": [
    "# Nom de l'exécution MLflow pour ce modèle\n",
    "run_name = \"LogisticRegression_TFIDF\"\n",
    "print(f\"\\nDébut de l'exécution MLflow : {run_name}\")\n",
    "\n",
    "# Démarrer une nouvelle exécution MLflow\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"ID de l'exécution MLflow : {run_id}\")\n",
    "\n",
    "    # --- Paramètres ---\n",
    "    # Paramètres du vectoriseur TF-IDF\n",
    "    tfidf_max_features = 10000  # Nombre maximum de caractéristiques à considérer\n",
    "    tfidf_ngram_range = (1, 3)  # Inclure les unigrammes, bigrammes et trigrammes\n",
    "\n",
    "    # Paramètres de la Régression Logistique\n",
    "    lr_C = 0.5  # Inverse de la force de régularisation (plus C est petit, plus la régularisation est forte)\n",
    "    lr_solver = \"saga\"  # Algorithme d'optimisation\n",
    "    lr_max_iter = 500  # Nombre maximum d'itérations pour la convergence\n",
    "    lr_class_weight = \"balanced\"  # Ajuster automatiquement les poids pour gérer le déséquilibre de classe\n",
    "\n",
    "    # Enregistrer les paramètres dans MLflow\n",
    "    print(\"Enregistrement des paramètres...\")\n",
    "    mlflow.log_param(\"type_vectoriseur\", \"TF-IDF\")\n",
    "    mlflow.log_param(\"tfidf_max_features\", tfidf_max_features)\n",
    "    mlflow.log_param(\n",
    "        \"tfidf_ngram_range\", str(tfidf_ngram_range)\n",
    "    )  # Tuple converti en string\n",
    "    mlflow.log_param(\"type_modele\", \"RegressionLogistique\")\n",
    "    mlflow.log_param(\"lr_C\", lr_C)\n",
    "    mlflow.log_param(\"lr_solver\", lr_solver)\n",
    "    mlflow.log_param(\"lr_max_iter\", lr_max_iter)\n",
    "    mlflow.log_param(\"lr_class_weight\", lr_class_weight)\n",
    "\n",
    "    # --- Extraction de caractéristiques (TF-IDF) ---\n",
    "    print(\"Entraînement du vectoriseur TF-IDF...\")\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=tfidf_max_features, ngram_range=tfidf_ngram_range\n",
    "    )\n",
    "    # Entraîner le vectoriseur sur les données d'entraînement et transformer\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    print(\n",
    "        f\"TF-IDF - Forme des données d'entraînement transformées : {X_train_tfidf.shape}\"\n",
    "    )\n",
    "\n",
    "    # Transformer les ensembles de validation et de test avec le vectoriseur entraîné\n",
    "    X_val_tfidf = vectorizer.transform(X_val)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    print(\n",
    "        f\"TF-IDF - Forme des données de validation transformées : {X_val_tfidf.shape}\"\n",
    "    )\n",
    "    print(f\"TF-IDF - Forme des données de test transformées : {X_test_tfidf.shape}\")\n",
    "\n",
    "    # Sauvegarder le vectoriseur entraîné localement\n",
    "    joblib.dump(vectorizer, VECTORIZER_FILENAME)\n",
    "    print(f\"Vectoriseur sauvegardé localement dans {VECTORIZER_FILENAME}\")\n",
    "\n",
    "    # Enregistrer le vectoriseur en tant qu'artefact MLflow\n",
    "    mlflow.log_artifact(VECTORIZER_FILENAME, artifact_path=\"vectoriseur\")\n",
    "    print(\"Vectoriseur enregistré comme artefact MLflow.\")\n",
    "\n",
    "    # Supprimer le fichier local après l'enregistrement (optionnel)\n",
    "    if os.path.exists(VECTORIZER_FILENAME):\n",
    "        os.remove(VECTORIZER_FILENAME)\n",
    "\n",
    "    # --- Entraînement du Modèle ---\n",
    "    print(\"Entraînement du modèle de Régression Logistique...\")\n",
    "    model = LogisticRegression(\n",
    "        C=lr_C,\n",
    "        solver=lr_solver,\n",
    "        max_iter=lr_max_iter,\n",
    "        class_weight=lr_class_weight,\n",
    "        random_state=42,  # Pour la reproductibilité\n",
    "    )\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    print(\"Entraînement du modèle terminé.\")\n",
    "\n",
    "    # --- Évaluation sur l'ensemble de Validation ---\n",
    "    print(\"Évaluation sur l'ensemble de validation...\")\n",
    "    y_val_pred = model.predict(X_val_tfidf)\n",
    "    # Probabilité de la classe positive (utile pour les courbes ROC, etc.)\n",
    "    y_val_pred_proba = model.predict_proba(X_val_tfidf)[:, 1]\n",
    "\n",
    "    # Calculer les métriques d'évaluation\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    val_recall = recall_score(y_val, y_val_pred, zero_division=0)\n",
    "    val_f1 = f1_score(y_val, y_val_pred, zero_division=0)\n",
    "\n",
    "    # Enregistrer les métriques de validation dans MLflow\n",
    "    print(\"Enregistrement des métriques de validation...\")\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "    mlflow.log_metric(\"val_precision\", val_precision)\n",
    "    mlflow.log_metric(\"val_recall\", val_recall)\n",
    "    mlflow.log_metric(\"val_f1\", val_f1)\n",
    "\n",
    "    print(f\"Validation Accuracy : {val_accuracy:.4f}\")\n",
    "    print(f\"Validation Précision : {val_precision:.4f}\")\n",
    "    print(f\"Validation Rappel : {val_recall:.4f}\")\n",
    "    print(f\"Validation F1-Score : {val_f1:.4f}\")\n",
    "\n",
    "    # --- Enregistrer le Modèle ---\n",
    "    print(\"Enregistrement du modèle entraîné...\")\n",
    "    mlflow.sklearn.log_model(model, artifact_path=\"modele-regression-logistique\")\n",
    "    print(\"Modèle enregistré avec succès.\")\n",
    "\n",
    "    # Générer et enregistrer le rapport de classification détaillé\n",
    "    val_report = classification_report(y_val, y_val_pred, output_dict=True)\n",
    "    mlflow.log_dict(val_report, \"rapport_classification_validation.json\")\n",
    "\n",
    "print(f\"\\nExécution MLflow {run_id} terminée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2b164",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc2_5_'></a>[Évaluation du modèle](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f3a59",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_5_1_'></a>[Évaluation sur les données de test](#toc0_)\n",
    "\n",
    "Cette cellule se concentre sur l'évaluation finale du modèle entraîné et enregistré via MLflow, en utilisant l'ensemble de test.\n",
    "\n",
    "Chargement du Modèle : Elle tente de charger le modèle de régression logistique à partir de son URI MLflow (logged_model_uri) en utilisant la fonction mlflow.sklearn.load_model.\n",
    "\n",
    "Prédictions et Évaluation : Une fois le modèle chargé, elle réalise des prédictions sur l'ensemble de test (X_test_tfidf) et calcule les métriques de performance standard (accuracy, precision, recall, F1-score).\n",
    "\n",
    "Affichage des Résultats : Les métriques de performance, le rapport de classification et la matrice de confusion pour l'ensemble de test sont imprimés, offrant une vue complète de la capacité généralisation du modèle.\n",
    "\n",
    "Journalisation dans MLflow : Enfin, les métriques de test et le rapport de classification détaillé sont journalisés rétroactivement dans la même exécution MLflow qui a enregistré le modèle. Ceci est crucial pour avoir toutes les informations de performance (validation et test) associées à une seule exécution dans l'interface utilisateur de MLflow, facilitant ainsi la comparaison et l'analyse.\n",
    "\n",
    "Cette étape est essentielle pour obtenir une estimation fiable des performances du modèle sur des données non vues, et pour documenter ces résultats dans MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d46a1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé avec succès depuis : runs:/d43f58cea498442dbbb0035cdc96cc82/modele-regression-logistique\n",
      "\n",
      "Performances sur l'ensemble de test :\n",
      "Test Accuracy : 0.8041\n",
      "Test Précision : 0.7972\n",
      "Test Rappel : 0.8156\n",
      "Test F1-Score : 0.8063\n",
      "\n",
      "Rapport de classification (ensemble de test) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80    120000\n",
      "           1       0.80      0.82      0.81    120000\n",
      "\n",
      "    accuracy                           0.80    240000\n",
      "   macro avg       0.80      0.80      0.80    240000\n",
      "weighted avg       0.80      0.80      0.80    240000\n",
      "\n",
      "\n",
      "Matrice de confusion (ensemble de test) :\n",
      "[[95110 24890]\n",
      " [22128 97872]]\n",
      "\n",
      "Métriques de test enregistrées dans l'exécution MLflow.\n"
     ]
    }
   ],
   "source": [
    "# Construire l'URI pour charger le modèle enregistré dans l'exécution MLflow précédente\n",
    "logged_model_uri = f\"runs:/{run_id}/modele-regression-logistique\"\n",
    "\n",
    "# Tenter de charger le modèle et d'évaluer ses performances sur l'ensemble de test\n",
    "try:\n",
    "    # Charger le modèle à partir de l'URI MLflow\n",
    "    loaded_model = mlflow.sklearn.load_model(logged_model_uri)\n",
    "    print(f\"Modèle chargé avec succès depuis : {logged_model_uri}\")\n",
    "\n",
    "    # Faire des prédictions sur l'ensemble de test (en utilisant la transformation TF-IDF existante)\n",
    "    y_test_pred = loaded_model.predict(X_test_tfidf)\n",
    "    # Obtenir les probabilités de la classe positive\n",
    "    y_test_pred_proba = loaded_model.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "    # Calculer les métriques de performance sur l'ensemble de test\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_recall = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "\n",
    "    print(\"\\nPerformances sur l'ensemble de test :\")\n",
    "    print(f\"Test Accuracy : {test_accuracy:.4f}\")\n",
    "    print(f\"Test Précision : {test_precision:.4f}\")\n",
    "    print(f\"Test Rappel : {test_recall:.4f}\")\n",
    "    print(f\"Test F1-Score : {test_f1:.4f}\")\n",
    "\n",
    "    print(\"\\nRapport de classification (ensemble de test) :\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    print(\"\\nMatrice de confusion (ensemble de test) :\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "    # --- Optionnel : Enregistrer les métriques de test dans la même exécution MLflow ---\n",
    "    # Pour cela, il faut utiliser le client MLflow car l'exécution est déjà terminée.\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    client.log_metric(run_id, \"test_accuracy\", test_accuracy)\n",
    "    client.log_metric(run_id, \"test_precision\", test_precision)\n",
    "    client.log_metric(run_id, \"test_recall\", test_recall)\n",
    "    client.log_metric(run_id, \"test_f1\", test_f1)\n",
    "    print(\"\\nMétriques de test enregistrées dans l'exécution MLflow.\")\n",
    "\n",
    "    # Enregistrer également le rapport de classification de test\n",
    "    test_report_dict = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "    client.log_dict(run_id, test_report_dict, \"rapport_classification_test.json\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"Erreur lors du chargement du modèle ou de l'évaluation sur l'ensemble de test : {e}\"\n",
    "    )\n",
    "    print(\n",
    "        \"Assurez-vous que l'ID de l'exécution est correct et que le modèle a été correctement enregistré.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f014eac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_5_2_'></a>[Comparaison avec un modèle naif](#toc0_)\n",
    "\n",
    "Cette cellule établit une \"ligne de base\" (baseline) pour l'évaluation des performances du modèle. Elle utilise un DummyClassifier avec la stratégie \"most_frequent\", ce qui signifie qu'il prédit toujours la classe majoritaire de l'ensemble d'entraînement. Cela permet de déterminer la performance minimale qu'un modèle devrait dépasser pour être considéré comme utile. Le classifieur dummy est entraîné sur les données TF-IDF d'entraînement, puis ses performances (accuracy, precision, recall, F1-score) sont calculées et affichées sur l'ensemble de test. Enfin, ces métriques de base sont comparées à celles du modèle de régression logistique entraîné, afin de quantifier le gain apporté par le modèle plus sophistiqué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "976ea7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performances de la ligne de base naïve (ensemble de test) :\n",
      "Accuracy de base : 0.5000\n",
      "Précision de base : 0.0000\n",
      "Rappel de base : 0.0000\n",
      "F1-Score de base : 0.0000\n",
      "\n",
      "Comparaison :\n",
      "Accuracy du modèle sur le test : 0.8041 vs Ligne de base : 0.5000\n",
      "F1-Score du modèle sur le test : 0.8063 vs Ligne de base : 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialiser un classifieur \"dummy\" (naïf) utilisant la stratégie de la classe la plus fréquente\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "# Entraîner le classifieur dummy (nécessaire même si la stratégie est simple, pour identifier la classe majoritaire)\n",
    "dummy_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test avec le classifieur dummy\n",
    "y_test_pred_dummy = dummy_clf.predict(X_test_tfidf)\n",
    "\n",
    "# Calculer les métriques de performance pour la ligne de base\n",
    "dummy_accuracy = accuracy_score(y_test, y_test_pred_dummy)\n",
    "dummy_precision = precision_score(y_test, y_test_pred_dummy, zero_division=0)\n",
    "dummy_recall = recall_score(y_test, y_test_pred_dummy, zero_division=0)\n",
    "dummy_f1 = f1_score(y_test, y_test_pred_dummy, zero_division=0)\n",
    "\n",
    "print(\"Performances de la ligne de base naïve (ensemble de test) :\")\n",
    "print(f\"Accuracy de base : {dummy_accuracy:.4f}\")\n",
    "print(f\"Précision de base : {dummy_precision:.4f}\")\n",
    "print(f\"Rappel de base : {dummy_recall:.4f}\")\n",
    "print(f\"F1-Score de base : {dummy_f1:.4f}\")\n",
    "\n",
    "print(\"\\nComparaison :\")\n",
    "print(\n",
    "    f\"Accuracy du modèle sur le test : {test_accuracy:.4f} vs Ligne de base : {dummy_accuracy:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"F1-Score du modèle sur le test : {test_f1:.4f} vs Ligne de base : {dummy_f1:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb0f72c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_5_3_'></a>[Enregistrement du model](#toc0_)\n",
    "\n",
    "Cette cellule enregistre le modèle entraîné et journalisé précédemment dans le registre de modèles MLflow. En fournissant l'URI du modèle à partir de l'exécution MLflow (logged_model_uri) et un nom (\"MODEL_SIMPLE\"), le modèle est catalogué et versionné au sein du registre. Cela permet une gestion centralisée des versions du modèle, facilitant son déploiement et sa réutilisation dans des environnements de production. Les informations clés du modèle enregistré (nom, version, étape actuelle) sont ensuite affichées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5010784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle enregistré avec succès :\n",
      "- Nom : MODEL_SIMPLE\n",
      "- Version : 5\n",
      "- Étape : None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'MODEL_SIMPLE' already exists. Creating a new version of this model...\n",
      "Created version '5' of model 'MODEL_SIMPLE'.\n"
     ]
    }
   ],
   "source": [
    "# Enregistrer le modèle entraîné dans le registre de modèles MLflow\n",
    "registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_model_uri,  # URI du modèle enregistré dans l'exécution précédente\n",
    "    name=\"MODEL_SIMPLE\",  # Nom sous lequel le modèle sera enregistré\n",
    ")\n",
    "\n",
    "print(\"Modèle enregistré avec succès :\")\n",
    "print(f\"- Nom : {registered_model_info.name}\")\n",
    "print(f\"- Version : {registered_model_info.version}\")\n",
    "print(f\"- Étape : {registered_model_info.current_stage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816c2829",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc2_6_'></a>[Dashboard MLFlow](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "427ce48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9cfca8",
   "metadata": {},
   "source": [
    "![Overview](./mlflow_screenshot/simple/Overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9482467",
   "metadata": {},
   "source": [
    "![Metrics](./mlflow_screenshot/simple/Metrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36019d12",
   "metadata": {},
   "source": [
    "![Compare Runs](./mlflow_screenshot/simple/Compare_runs.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
