{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f98536",
   "metadata": {},
   "source": [
    "# Projet 7 : Réalisez une analyse de sentiments grâce au Deep Learning\n",
    "# Modèle sur mesure avancé\n",
    "\n",
    "[Lien OpenClassroom](https://openclassrooms.com/fr/paths/795/projects/1516/1578-mission)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a7d68b",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Imports](#toc1_)    \n",
    "- [Chargement des données](#toc2_)    \n",
    "  - [Chargement du fichier csv](#toc2_1_)    \n",
    "  - [Découpage du jeu de données](#toc2_2_)    \n",
    "- [Préparation et Tests](#toc3_)    \n",
    "  - [Variables Globales](#toc3_1_)    \n",
    "  - [Fonctions de préprocessing](#toc3_2_)    \n",
    "  - [ Test des approches de preprocessing](#toc3_3_)    \n",
    "  - [Application du meilleur préprocessing](#toc3_4_)    \n",
    "  - [Création d'un Tokenizer](#toc3_5_)    \n",
    "  - [Sauvegarde du Tokenizer](#toc3_6_)    \n",
    "  - [Chargement de GloVe Embeddings](#toc3_7_)    \n",
    "  - [Création du modèle](#toc3_8_)    \n",
    "- [Experiment 1: LSTM avec GloVe Embeddings](#toc4_)    \n",
    "  - [MLFlow Setup](#toc4_1_)    \n",
    "  - [Entrainement du modèle avec MLFlow](#toc4_2_)    \n",
    "- [Experiment 2: LSTM avec Embeddings Vièrges Entrainable](#toc5_)    \n",
    "  - [Entrainement du modèle avec MLFlow](#toc5_1_)    \n",
    "- [Evaluation et Selection](#toc6_)    \n",
    "  - [Selection du meilleur modèle (val_accuracy)](#toc6_1_)    \n",
    "  - [Evaluation du modèle sur les données de Test](#toc6_2_)    \n",
    "  - [Enregistrement du model](#toc6_3_)    \n",
    "- [Dashboard MLFlow](#toc7_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8783740e",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc1_'></a>[Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1df1d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Embedding,\n",
    "    Bidirectional,\n",
    "    Input,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import mlflow\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import contractions\n",
    "\n",
    "try:\n",
    "    stopwords.words(\"english\")\n",
    "except LookupError:\n",
    "    nltk.download(\"stopwords\")\n",
    "try:\n",
    "    word_tokenize(\"test\")\n",
    "except LookupError:\n",
    "    nltk.download(\"punkt\")\n",
    "try:\n",
    "    WordNetLemmatizer().lemmatize(\"cats\")\n",
    "except LookupError:\n",
    "    nltk.download(\"wordnet\")\n",
    "    nltk.download(\"omw-1.4\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641c0b8",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc2_'></a>[Chargement des données](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4789f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_1_'></a>[Chargement du fichier csv](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f48e53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tweet",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "01a47e52-f479-4114-8f28-81ed1d96c28c",
       "rows": [
        [
         "1503830",
         "@teach24_7 1) every now &amp; again, for fun!  2) dunno about that buddy, game 2 &amp; kobes is still beasting  got scary close though...",
         "1"
        ],
        [
         "177381",
         "maybe someday. i lova ya, friends!! my computer sucks  listening to coldplay&lt;3 tomorrow meet my bbff",
         "0"
        ],
        [
         "340226",
         "@MisterRo Does this mean that you aren't going to help me either?  Sniff.",
         "0"
        ],
        [
         "1450680",
         "@qillerm well... someone actually complained about it, and i happen to know about it  yeap, please do. not finalized",
         "1"
        ],
        [
         "816047",
         "@stokez haha i know!  ahh cant wait to go home!",
         "1"
        ],
        [
         "1109101",
         "goodnight everybody!!! buona notte!! ",
         "1"
        ],
        [
         "96580",
         "I need to grow balls and learn to kiss people sober. I miss you already. ",
         "0"
        ],
        [
         "910046",
         "having a creative party with me, myself, and moi ",
         "1"
        ],
        [
         "325867",
         "noticing some of the long-time java guys seem, well, less happy about JavaOne this year ",
         "0"
        ],
        [
         "121454",
         "bah.. it's monday already ",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503830</th>\n",
       "      <td>@teach24_7 1) every now &amp;amp; again, for fun! ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177381</th>\n",
       "      <td>maybe someday. i lova ya, friends!! my compute...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340226</th>\n",
       "      <td>@MisterRo Does this mean that you aren't going...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450680</th>\n",
       "      <td>@qillerm well... someone actually complained a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816047</th>\n",
       "      <td>@stokez haha i know!  ahh cant wait to go home!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109101</th>\n",
       "      <td>goodnight everybody!!! buona notte!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96580</th>\n",
       "      <td>I need to grow balls and learn to kiss people ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910046</th>\n",
       "      <td>having a creative party with me, myself, and moi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325867</th>\n",
       "      <td>noticing some of the long-time java guys seem,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121454</th>\n",
       "      <td>bah.. it's monday already</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  label\n",
       "1503830  @teach24_7 1) every now &amp; again, for fun! ...      1\n",
       "177381   maybe someday. i lova ya, friends!! my compute...      0\n",
       "340226   @MisterRo Does this mean that you aren't going...      0\n",
       "1450680  @qillerm well... someone actually complained a...      1\n",
       "816047     @stokez haha i know!  ahh cant wait to go home!      1\n",
       "1109101              goodnight everybody!!! buona notte!!       1\n",
       "96580    I need to grow balls and learn to kiss people ...      0\n",
       "910046   having a creative party with me, myself, and moi       1\n",
       "325867   noticing some of the long-time java guys seem,...      0\n",
       "121454                          bah.. it's monday already       0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"./data.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca708ed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc2_2_'></a>[Découpage du jeu de données](#toc0_)\n",
    "\n",
    "Cette cellule est une répétition de la logique de division des données déjà vue. Elle redéfinit et effectue le découpage du jeu de données en trois parties : entraînement, validation et test. L'objectif est de garantir que les données sont correctement et stratifiquement séparées pour le développement et l'évaluation des modèles, avec des proportions fixes (70% entraînement, 15% validation, 15% test). La séparation stratifiée est cruciale pour maintenir la distribution des classes de sentiment dans chaque ensemble, ce qui est important pour les jeux de données déséquilibrés. Enfin, les dimensions des ensembles et la distribution des sentiments sont imprimées pour vérification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2a6dd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Division des données terminée :\n",
      "Taille de l'ensemble d'entraînement :   X=(1120000,), y=(1120000,)\n",
      "Taille de l'ensemble de validation : X=(240000,), y=(240000,)\n",
      "Taille de l'ensemble de test :       X=(240000,), y=(240000,)\n",
      "\n",
      "Distribution des sentiments dans les ensembles :\n",
      "Entraînement :\n",
      " label\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Validation :\n",
      " label\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Test :\n",
      " label\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Définir les features (X) et les labels (y)\n",
    "X = df[\"tweet\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Définir les tailles des ensembles de test et de validation\n",
    "TEST_SIZE = 0.15\n",
    "VALIDATION_SIZE = 0.15  # Relatif à la taille originale du dataset\n",
    "\n",
    "# Première division : entraînement vs. (validation + test)\n",
    "# X_temp et y_temp contiennent les données destinées aux ensembles de validation et de test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=(VALIDATION_SIZE + TEST_SIZE),  # Taille combinée de l'ensemble temporaire\n",
    "    random_state=42,  # Pour garantir la reproductibilité des divisions\n",
    "    stratify=y,  # Pour maintenir la même distribution de labels dans les sous-ensembles\n",
    ")\n",
    "\n",
    "# Calculer la proportion de l'ensemble de validation par rapport à l'ensemble temporaire\n",
    "val_split_ratio = VALIDATION_SIZE / (VALIDATION_SIZE + TEST_SIZE)\n",
    "\n",
    "# Deuxième division : validation vs. test à partir de l'ensemble temporaire\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=(\n",
    "        1 - val_split_ratio\n",
    "    ),  # La portion restante de X_temp devient l'ensemble de test\n",
    "    random_state=42,\n",
    "    stratify=y_temp,  # Maintenir la distribution des labels dans le sous-ensemble temporaire\n",
    ")\n",
    "\n",
    "# Afficher les formes des ensembles après la division\n",
    "print(\"Division des données terminée :\")\n",
    "print(f\"Taille de l'ensemble d'entraînement :   X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Taille de l'ensemble de validation : X={X_val.shape}, y={y_val.shape}\")\n",
    "print(f\"Taille de l'ensemble de test :       X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "# Afficher la distribution des sentiments dans chaque ensemble pour vérification\n",
    "print(\"\\nDistribution des sentiments dans les ensembles :\")\n",
    "print(\"Entraînement :\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Validation :\\n\", y_val.value_counts(normalize=True))\n",
    "print(\"Test :\\n\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a64bc",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc3_'></a>[Préparation et Tests](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309cbc8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc3_1_'></a>[Variables Globales](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68b6d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taille du vocabulaire à utiliser pour la tokenisation\n",
    "VOCAB_SIZE = 300\n",
    "# Longueur maximale des séquences de texte après padding/troncation\n",
    "MAX_SEQUENCE_LENGTH = 20\n",
    "\n",
    "# Chemin vers le fichier d'embeddings GloVe pré-entraînés\n",
    "GLOVE_PATH = \"./glove.6B.300d.txt\"\n",
    "# Dimension des vecteurs d'embeddings GloVe\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "# Nombre d'époques d'entraînement pour le modèle\n",
    "EPOCHS = 10\n",
    "# Taille du lot (batch size) pour l'entraînement\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# Chemin d'artefact MLflow pour le tokenizer entraîné\n",
    "TOKENIZER_ARTIFACT_PATH = \"tokenizer\"\n",
    "\n",
    "# Chemin d'artefact MLflow pour le modèle de réseau de neurones entraîné\n",
    "MODEL_ARTIFACT_PATH = \"model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f18b48",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc3_2_'></a>[Fonctions de préprocessing](#toc0_)\n",
    "\n",
    "Cette cellule est une redéfinition des trois fonctions de prétraitement du texte (preprocess_full, preprocess_no_stopwords, preprocess_none) qui ont déjà été présentées. Elles sont cruciales pour la préparation des données textuelles avant l'entraînement des modèles de NLP.\n",
    "\n",
    "preprocess_full : Effectue un nettoyage intensif, incluant la conversion en minuscules, l'expansion des contractions, la suppression des URLs, mentions, hashtags, nombres et caractères spéciaux, suivie de la tokenisation, de la suppression des mots vides et de la lemmatisation.\n",
    "\n",
    "preprocess_no_stopwords : Similaire à preprocess_full, mais elle maintient les mots vides dans le texte final.\n",
    "\n",
    "preprocess_none : Ne réalise aucun prétraitement, renvoyant le texte tel quel.\n",
    "\n",
    "La présence répétée de cette cellule suggère qu'elle pourrait être exécutée à plusieurs reprises ou qu'elle est destinée à être un bloc de code réutilisable pour différents pipelines de modélisation dans le notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ede41854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_full(text):\n",
    "    \"\"\"\n",
    "    Applique toutes les étapes de nettoyage du texte, y compris la suppression des mots vides.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Convertir le texte en minuscules\n",
    "    text = text.lower()\n",
    "    # Étendre les contractions (ex: \"don't\" -> \"do not\")\n",
    "    text = contractions.fix(text)\n",
    "    # Supprimer les URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    # Supprimer les mentions (@user)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    # Supprimer les hashtags (#tag)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    # Supprimer les nombres\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    # Supprimer les caractères spéciaux et la ponctuation (ne garder que les lettres et espaces)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "\n",
    "    # Tokeniser le texte en mots\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = []\n",
    "    for word in tokens:\n",
    "        # Supprimer les mots vides et les mots d'une seule lettre, puis lemmatiser\n",
    "        if len(word) > 1 and word not in stop_words:\n",
    "            lemma = lemmatizer.lemmatize(word)\n",
    "            cleaned_tokens.append(lemma)\n",
    "    # Rejoindre les jetons nettoyés en une seule chaîne\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "\n",
    "def preprocess_no_stopwords(text):\n",
    "    \"\"\"\n",
    "    Applique toutes les étapes de nettoyage du texte, SAUF la suppression des mots vides.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = contractions.fix(text)\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = []\n",
    "    for word in tokens:\n",
    "        # Lemmatiser sans supprimer les mots vides\n",
    "        if len(word) > 1:\n",
    "            lemma = lemmatizer.lemmatize(word)\n",
    "            cleaned_tokens.append(lemma)\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "\n",
    "def preprocess_none(text):\n",
    "    \"\"\"\n",
    "    N'applique aucun prétraitement, retourne le texte tel quel (ou une chaîne vide si ce n'est pas une chaîne).\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ecf454",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc3_3_'></a>[ Test des approches de preprocessing](#toc0_)\n",
    "\n",
    "Cette cellule implémente le pipeline d'entraînement et d'évaluation pour un modèle de réseau de neurones LSTM, en explorant l'impact des différentes stratégies de prétraitement du texte.\n",
    "\n",
    "create_lstm_model : Définit l'architecture du modèle LSTM. Il inclut une couche d'embedding qui peut soit utiliser des poids pré-entraînés (GloVe) et être figée (trainable=False), soit être initialisée aléatoirement et entraînée (trainable=True). Le modèle se compose ensuite d'une couche LSTM et d'une couche Dense de sortie avec activation sigmoïde pour la classification binaire.\n",
    "\n",
    "train_eval_lstm : Gère l'ensemble du processus de préparation des données et d'entraînement/évaluation pour les modèles LSTM :\n",
    "\n",
    "- Tokenisation et Padding : Crée un Tokenizer Keras pour convertir les textes en séquences numériques et padde ces séquences pour qu'elles aient une longueur uniforme (MAX_SEQUENCE_LENGTH).\n",
    "\n",
    "- Chargement GloVe : La fonction tente de charger les embeddings GloVe et de construire une matrice d'embedding où chaque mot du vocabulaire du tokenizer est mappé à son vecteur GloVe correspondant.\n",
    "\n",
    "- Construction et Entraînement du Modèle : Appelle create_lstm_model avec les paramètres appropriés (embeddings GloVe ou entraînables). Le modèle est ensuite entraîné sur les données padées.\n",
    "\n",
    "- Évaluation : Prédit sur l'ensemble de test et calcule l'exactitude (accuracy) et le score F1.\n",
    "\n",
    "Boucle de Benchmarking : La cellule itère sur les mêmes configurations de prétraitement que précédemment (preprocess_none, preprocess_no_stopwords, preprocess_full). Pour chaque configuration, elle exécute l'entraînement et l'évaluation du LSTM avec les embeddings GloVe. Les résultats sont stockés dans results_log.\n",
    "\n",
    "L'objectif est d'évaluer la performance du modèle LSTM sous différentes conditions de prétraitement, afin de déterminer la combinaison optimale pour l'analyse de sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "163fa943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BENCHMARKING AVEC PRÉTRAITEMENT : Sans Prétraitement ---\n",
      "Entraînement LSTM avec GloVe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/17 19:29:55 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '2ee68e49a35342dead68760f3271964b', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "2025/06/17 19:29:55 WARNING mlflow.tensorflow: Encountered unexpected error while inferring batch size from training dataset: Sequential model 'sequential_5' has no defined input shape yet.\n",
      "2025/06/17 19:29:55 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trouvé 400001 vecteurs de mots dans ./glove.6B.300d.txt.\n",
      "Création de la matrice d'embeddings...\n",
      "Converti 287 mots (12 manquants)\n",
      "Forme de la matrice d'embeddings : (300, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      "LSTM GloVe Accuracy: 0.7382, F1-Score: 0.7451\n",
      "\n",
      "--- BENCHMARKING AVEC PRÉTRAITEMENT : Tout Sauf Mots Vides ---\n",
      "Entraînement LSTM avec GloVe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/17 19:33:51 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'c43cd9b16aec43cbacc8b59b5711503e', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "2025/06/17 19:33:51 WARNING mlflow.tensorflow: Encountered unexpected error while inferring batch size from training dataset: Sequential model 'sequential_6' has no defined input shape yet.\n",
      "2025/06/17 19:33:51 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trouvé 400001 vecteurs de mots dans ./glove.6B.300d.txt.\n",
      "Création de la matrice d'embeddings...\n",
      "Converti 298 mots (1 manquants)\n",
      "Forme de la matrice d'embeddings : (300, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      "LSTM GloVe Accuracy: 0.7511, F1-Score: 0.7533\n",
      "\n",
      "--- BENCHMARKING AVEC PRÉTRAITEMENT : Tout Prétraitement ---\n",
      "Entraînement LSTM avec GloVe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/17 19:37:35 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '861671e563cd4ecebe426efdce4e33e4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "2025/06/17 19:37:35 WARNING mlflow.tensorflow: Encountered unexpected error while inferring batch size from training dataset: Sequential model 'sequential_7' has no defined input shape yet.\n",
      "2025/06/17 19:37:35 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trouvé 400001 vecteurs de mots dans ./glove.6B.300d.txt.\n",
      "Création de la matrice d'embeddings...\n",
      "Converti 297 mots (2 manquants)\n",
      "Forme de la matrice d'embeddings : (300, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
      "LSTM GloVe Accuracy: 0.7060, F1-Score: 0.7111\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_model(\n",
    "    vocab_size, embedding_dim, max_len, embedding_matrix=None, trainable_embedding=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Crée un modèle LSTM de base pour la classification binaire.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Taille du vocabulaire.\n",
    "        embedding_dim (int): Dimension des embeddings.\n",
    "        max_len (int): Longueur maximale des séquences.\n",
    "        embedding_matrix (np.array, optional): Matrice d'embeddings pré-entraînés.\n",
    "        trainable_embedding (bool, optional): Indique si la couche d'embedding doit être entraînable.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    if embedding_matrix is not None:\n",
    "        # Utiliser des embeddings pré-entraînés (non entraînables par défaut)\n",
    "        model.add(\n",
    "            Embedding(\n",
    "                vocab_size,\n",
    "                embedding_dim,\n",
    "                weights=[embedding_matrix],\n",
    "                input_length=max_len,\n",
    "                trainable=False,  # Les poids des embeddings ne sont pas mis à jour\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        # Utiliser une couche d'embedding entraînable à partir de zéro\n",
    "        model.add(\n",
    "            Embedding(\n",
    "                vocab_size,\n",
    "                embedding_dim,\n",
    "                input_length=max_len,\n",
    "                trainable=trainable_embedding,\n",
    "            )\n",
    "        )\n",
    "    # Ajouter une couche LSTM\n",
    "    model.add(LSTM(32))\n",
    "    # Ajouter une couche de sortie Dense avec activation sigmoïde pour classification binaire\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compiler le modèle\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_eval_lstm(\n",
    "    X_train_processed, y_train_labels, X_test_processed, y_test_labels, use_glove=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Entraîne et évalue un modèle LSTM, avec ou sans embeddings GloVe pré-entraînés.\n",
    "\n",
    "    Args:\n",
    "        X_train_processed (list): Textes d'entraînement prétraités.\n",
    "        y_train_labels (pd.Series): Labels d'entraînement.\n",
    "        X_test_processed (list): Textes de test prétraités.\n",
    "        y_test_labels (pd.Series): Labels de test.\n",
    "        use_glove (bool, optional): Utiliser les embeddings GloVe si True, sinon entraîner les embeddings.\n",
    "    \"\"\"\n",
    "    print(\n",
    "        f\"Entraînement LSTM {'avec GloVe' if use_glove else 'avec Embeddings entraînables'}\"\n",
    "    )\n",
    "\n",
    "    # Initialiser et entraîner le tokenizer sur les données d'entraînement\n",
    "    tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<oov>\")\n",
    "    tokenizer.fit_on_texts(X_train_processed)\n",
    "    word_index = tokenizer.word_index\n",
    "    # Ajuster la taille réelle du vocabulaire si elle est inférieure à VOCAB_SIZE\n",
    "    vocab_size = min(VOCAB_SIZE, len(word_index) + 1)\n",
    "\n",
    "    # Convertir les textes en séquences numériques\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train_processed)\n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test_processed)\n",
    "    # Padder/tronquer les séquences pour avoir une longueur fixe\n",
    "    X_train_pad = pad_sequences(\n",
    "        X_train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\"\n",
    "    )\n",
    "    X_test_pad = pad_sequences(\n",
    "        X_test_seq, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\"\n",
    "    )\n",
    "\n",
    "    embedding_matrix = None\n",
    "    if use_glove:\n",
    "        # Charger les embeddings GloVe\n",
    "        embeddings_index = {}\n",
    "        try:\n",
    "            with open(GLOVE_PATH, encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    values = line.split()\n",
    "                    word = values[0]\n",
    "                    coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "                    embeddings_index[word] = coefs\n",
    "            print(f\"Trouvé {len(embeddings_index)} vecteurs de mots dans {GLOVE_PATH}.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Erreur : Fichier GloVe introuvable à {GLOVE_PATH}\")\n",
    "            print(\"Expérience GloVe ignorée.\")\n",
    "            embeddings_index = None\n",
    "        except Exception as e:\n",
    "            print(f\"Une erreur est survenue lors du chargement du fichier GloVe : {e}\")\n",
    "            embeddings_index = None\n",
    "\n",
    "        if embeddings_index:\n",
    "            print(\"Création de la matrice d'embeddings...\")\n",
    "            # Initialiser la matrice d'embeddings avec des zéros\n",
    "            embedding_matrix = np.zeros(\n",
    "                (min(VOCAB_SIZE, len(tokenizer.word_index) + 1), EMBEDDING_DIM)\n",
    "            )\n",
    "            hits = 0\n",
    "            misses = 0\n",
    "            # Remplir la matrice avec les vecteurs GloVe pour les mots du vocabulaire du tokenizer\n",
    "            for word, i in tokenizer.word_index.items():\n",
    "                if (\n",
    "                    i >= vocab_size\n",
    "                ):  # Ignorer les mots au-delà de la limite du vocabulaire\n",
    "                    continue\n",
    "                embedding_vector = embeddings_index.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "                    hits += 1\n",
    "                else:\n",
    "                    misses += 1\n",
    "            print(f\"Converti {hits} mots ({misses} manquants)\")\n",
    "            print(f\"Forme de la matrice d'embeddings : {embedding_matrix.shape}\")\n",
    "\n",
    "        # Créer le modèle LSTM avec les embeddings GloVe\n",
    "        model = create_lstm_model(\n",
    "            vocab_size,\n",
    "            EMBEDDING_DIM,\n",
    "            MAX_SEQUENCE_LENGTH,\n",
    "            embedding_matrix=embedding_matrix,\n",
    "            trainable_embedding=False,  # Embeddings GloVe non entraînables\n",
    "        )\n",
    "    else:\n",
    "        # Créer le modèle LSTM avec des embeddings entraînables aléatoirement initialisés\n",
    "        model = create_lstm_model(\n",
    "            vocab_size, EMBEDDING_DIM, MAX_SEQUENCE_LENGTH, trainable_embedding=True\n",
    "        )\n",
    "\n",
    "    # Entraîner le modèle LSTM\n",
    "    model.fit(\n",
    "        X_train_pad,\n",
    "        y_train_labels,\n",
    "        epochs=2,  # Époques réduites pour un exemple rapide\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.1,\n",
    "        verbose=0,  # Ne pas afficher la barre de progression\n",
    "    )\n",
    "\n",
    "    # Faire des prédictions sur l'ensemble de test\n",
    "    predictions_proba = model.predict(X_test_pad)\n",
    "    predictions = (\n",
    "        (predictions_proba > 0.5).astype(int).flatten()\n",
    "    )  # Convertir les probabilités en classes\n",
    "    true_labels = y_test_labels\n",
    "\n",
    "    # Calculer l'exactitude et le score F1\n",
    "    acc = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions, average=\"binary\")\n",
    "    return acc, f1\n",
    "\n",
    "\n",
    "# Définir les différentes configurations de prétraitement à tester\n",
    "preprocessing_configs = {\n",
    "    \"Sans Prétraitement\": preprocess_none,\n",
    "    \"Tout Sauf Mots Vides\": preprocess_no_stopwords,\n",
    "    \"Tout Prétraitement\": preprocess_full,\n",
    "}\n",
    "\n",
    "results_log = []  # Liste pour stocker les résultats de l'évaluation\n",
    "\n",
    "# Boucler sur chaque configuration de prétraitement\n",
    "for pp_name, pp_function in preprocessing_configs.items():\n",
    "    print(f\"\\n--- BENCHMARKING AVEC PRÉTRAITEMENT : {pp_name} ---\")\n",
    "\n",
    "    # Appliquer la fonction de prétraitement aux ensembles d'entraînement et de test\n",
    "    current_X_train = [pp_function(text) for text in X_train]\n",
    "    current_X_test = [pp_function(text) for text in X_test]\n",
    "\n",
    "    # --- LSTM avec Embeddings GloVe ---\n",
    "    acc, f1 = train_eval_lstm(\n",
    "        current_X_train, y_train, current_X_test, y_test, use_glove=True\n",
    "    )\n",
    "    results_log.append(\n",
    "        {\n",
    "            \"Modèle\": \"LSTM (GloVe Emb)\",.\n",
    "            \"Prétraitement\": pp_name,\n",
    "            \"Accuracy\": acc,\n",
    "            \"F1-Score\": f1,\n",
    "        }\n",
    "    )\n",
    "    print(f\"LSTM GloVe Accuracy: {acc:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab79a113",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc3_4_'></a>[Application du meilleur préprocessing](#toc0_)\n",
    "\n",
    "Cette cellule applique une étape de prétraitement spécifique aux ensembles de données textuelles (X_train, X_val, X_test). Elle utilise la fonction preprocess_no_stopwords qui nettoie les textes (minuscules, expansion des contractions, suppression des URLs, mentions, hashtags, nombres et ponctuation) mais, comme son nom l'indique, ne supprime pas les mots vides (stop words). Cela prépare les données pour des modèles qui pourraient bénéficier de la présence des mots vides pour le contexte, comme certains modèles de réseaux de neurones ou d'embeddings de mots qui capturent la sémantique de phrases entières."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d659f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la fonction de prétraitement 'preprocess_no_stopwords' aux ensembles d'entraînement, de validation et de test\n",
    "# Cette fonction nettoie le texte mais conserve les mots vides.\n",
    "X_train = [preprocess_no_stopwords(text) for text in X_train]\n",
    "X_val = [preprocess_no_stopwords(text) for text in X_val]\n",
    "X_test = [preprocess_no_stopwords(text) for text in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e45af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc3_5_'></a>[Création d'un Tokenizer](#toc0_)\n",
    "\n",
    "Cette cellule gère la phase de tokenisation et de séquençage des données textuelles. Elle utilise le Tokenizer de Keras pour convertir les mots en identifiants numériques. Le tokenizer est ajusté uniquement sur l'ensemble d'entraînement pour éviter d'introduire des informations du test ou de la validation. Ensuite, tous les ensembles (entraînement, validation, test) sont transformés en séquences d'entiers et sont uniformisés en longueur via le padding (pad_sequences). Cela est essentiel pour préparer les données textuelles à être utilisées comme entrée pour des modèles de réseaux de neurones récurrents comme les LSTMs, qui nécessitent des entrées de longueur fixe. La taille effective du vocabulaire est également calculée et affichée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1754d1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire réelle utilisée : 300\n",
      "Forme des séquences d'entraînement padées : (1120000, 20)\n",
      "Forme des séquences de validation padées : (240000, 20)\n",
      "Forme des séquences de test padées : (240000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Initialiser le tokenizer Keras avec une taille de vocabulaire limitée et un jeton pour les mots hors-vocabulaire\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "\n",
    "# Entraîner le tokenizer UNIQUEMENT sur les données d'entraînement pour éviter les fuites de données\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convertir les textes en séquences d'entiers basées sur le vocabulaire appris\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Padder les séquences pour garantir une longueur uniforme (remplir après, tronquer après)\n",
    "X_train_pad = pad_sequences(\n",
    "    X_train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "X_val_pad = pad_sequences(\n",
    "    X_val_seq, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "X_test_pad = pad_sequences(\n",
    "    X_test_seq, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "\n",
    "# Calculer la taille réelle du vocabulaire (incluant le jeton de padding)\n",
    "# Limité par VOCAB_SIZE ou la taille réelle du vocabulaire si elle est plus petite\n",
    "actual_vocab_size = min(VOCAB_SIZE, len(tokenizer.word_index) + 1)\n",
    "print(f\"Taille du vocabulaire réelle utilisée : {actual_vocab_size}\")\n",
    "print(f\"Forme des séquences d'entraînement padées : {X_train_pad.shape}\")\n",
    "print(f\"Forme des séquences de validation padées : {X_val_pad.shape}\")\n",
    "print(f\"Forme des séquences de test padées : {X_test_pad.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8e9e8f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc3_7_'></a>[Chargement de GloVe Embeddings](#toc0_)\n",
    "\n",
    "Cette cellule est dédiée à la préparation de la matrice d'embeddings pré-entraînés GloVe. Elle tente d'abord de charger les vecteurs de mots depuis le fichier spécifié par GLOVE_PATH. Si le fichier est trouvé, il est parcouru ligne par ligne pour extraire les mots et leurs vecteurs correspondants, stockés dans un dictionnaire embeddings_index. En cas d'erreur (fichier non trouvé ou autre), un message est affiché et le processus GloVe est ignoré.\n",
    "\n",
    "Après le chargement (réussi), une matrice d'embedding (embedding_matrix) est créée. Cette matrice est dimensionnée pour correspondre au vocabulaire de notre tokenizer (actual_vocab_size) et à la dimension des embeddings (EMBEDDING_DIM). Elle est ensuite remplie : pour chaque mot présent dans le vocabulaire de notre tokenizer et trouvé dans les embeddings GloVe, le vecteur GloVe correspondant est copié dans la matrice. Les mots du vocabulaire du tokenizer qui ne sont pas trouvés dans GloVe sont représentés par des vecteurs de zéros dans la matrice d'embedding. Le nombre de \"hits\" (mots trouvés) et de \"misses\" (mots non trouvés) est affiché pour donner une idée de la couverture du vocabulaire par GloVe. Cette matrice sera ensuite utilisée pour initialiser la couche d'embedding de notre modèle de réseau de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "142412d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trouvé 400001 vecteurs de mots dans ./glove.6B.300d.txt.\n",
      "Création de la matrice d'embeddings...\n",
      "Converti 298 mots (1 manquants)\n",
      "Forme de la matrice d'embeddings : (300, 300)\n"
     ]
    }
   ],
   "source": [
    "# Initialiser un dictionnaire pour stocker les embeddings GloVe\n",
    "embeddings_index = {}\n",
    "try:\n",
    "    # Ouvrir le fichier GloVe et parser chaque ligne\n",
    "    with open(GLOVE_PATH, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "            embeddings_index[word] = coefs\n",
    "    print(f\"Trouvé {len(embeddings_index)} vecteurs de mots dans {GLOVE_PATH}.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erreur : Fichier GloVe introuvable à {GLOVE_PATH}\")\n",
    "    print(\"Expérience GloVe ignorée.\")\n",
    "    embeddings_index = None  # S'assurer que la variable existe mais est None\n",
    "except Exception as e:\n",
    "    print(f\"Une erreur est survenue lors du chargement du fichier GloVe : {e}\")\n",
    "    embeddings_index = None\n",
    "\n",
    "# Créer la matrice d'embeddings à partir des embeddings GloVe et du vocabulaire du tokenizer\n",
    "embedding_matrix = None\n",
    "if embeddings_index:\n",
    "    print(\"Création de la matrice d'embeddings...\")\n",
    "    # Initialiser la matrice d'embeddings avec des zéros\n",
    "    embedding_matrix = np.zeros((actual_vocab_size, EMBEDDING_DIM))\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    # Remplir la matrice avec les vecteurs GloVe pour les mots présents dans le vocabulaire de notre tokenizer\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if (\n",
    "            i >= actual_vocab_size\n",
    "        ):  # Ignorer les mots au-delà de la taille de vocabulaire définie\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Les mots trouvés dans GloVe reçoivent leur vecteur\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            # Les mots non trouvés dans GloVe restent avec un vecteur de zéros\n",
    "            misses += 1\n",
    "    print(f\"Converti {hits} mots ({misses} manquants)\")\n",
    "    print(f\"Forme de la matrice d'embeddings : {embedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe4456",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc3_8_'></a>[Création du modèle](#toc0_)\n",
    "\n",
    "Cette cellule définit la fonction build_lstm_model qui construit une architecture de réseau de neurones LSTM pour la classification de texte. Le modèle intègre une couche d'embedding qui peut être initialisée avec des poids pré-entraînés (par exemple, GloVe) et figée, ou entraînée à partir de zéro. L'architecture optimisée comprend deux couches LSTM (la première retournant des séquences, la seconde non), suivies d'une couche Dense avec activation ReLU, d'une couche Dropout pour la régularisation, et enfin d'une couche Dense de sortie avec activation sigmoïde pour la classification binaire. Le modèle est compilé avec une perte de 'binary_crossentropy', l'optimiseur 'adamax' et la métrique 'accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b53c9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    max_length,\n",
    "    embedding_matrix=None,\n",
    "    is_embedding_trainable=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Construit un modèle LSTM optimisé pour la classification de texte.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Taille du vocabulaire.\n",
    "        embedding_dim (int): Dimension des embeddings.\n",
    "        max_length (int): Longueur maximale des séquences d'entrée.\n",
    "        embedding_matrix (np.array, optional): Matrice d'embeddings pré-entraînés.\n",
    "        is_embedding_trainable (bool, optional): Si la couche d'embedding doit être entraînable.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Couche d'entrée pour définir la forme des séquences\n",
    "    model.add(Input(shape=(max_length,)))\n",
    "\n",
    "    # Couche d'embedding\n",
    "    if embedding_matrix is not None:\n",
    "        print(\"Utilisation de la matrice d'embeddings pré-entraînés.\")\n",
    "        model.add(\n",
    "            Embedding(\n",
    "                input_dim=vocab_size,\n",
    "                output_dim=embedding_dim,\n",
    "                weights=[embedding_matrix],  # Utiliser les poids pré-entraînés\n",
    "                input_length=max_length,\n",
    "                trainable=is_embedding_trainable,  # Définir si les poids sont mis à jour\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(\"Utilisation d'une couche d'embeddings entraînables.\")\n",
    "        model.add(\n",
    "            Embedding(\n",
    "                input_dim=vocab_size,\n",
    "                output_dim=embedding_dim,\n",
    "                input_length=max_length,\n",
    "                trainable=is_embedding_trainable,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Deuxième couche LSTM avec dropout récurrent (ne retourne pas de séquences)\n",
    "    model.add(Bidirectional(LSTM(64, dropout=0.1, recurrent_dropout=0.1)))\n",
    "\n",
    "    # Couche de sortie Dense pour la classification binaire (activation sigmoïde)\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compiler le modèle avec une fonction de perte binaire, un optimiseur et des métriques\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adamax\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d5ab8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc4_1_'></a>[MLFlow Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f742b283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expérience MLflow définie sur : 'Tweet Sentiment Analysis - Advanced DL'\n"
     ]
    }
   ],
   "source": [
    "# Nom de l'expérience MLflow pour le suivi des modèles de Deep Learning avancés\n",
    "EXPERIMENT_NAME = \"Tweet Sentiment Analysis - Advanced DL\"\n",
    "# Définir l'expérience MLflow actuelle\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "print(f\"Expérience MLflow définie sur : '{EXPERIMENT_NAME}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14f25c2",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc4_'></a>[Experiment 1: LSTM avec GloVe Embeddings](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db11349",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc4_2_'></a>[Entrainement du modèle avec MLFlow](#toc0_)\n",
    "\n",
    "Cette cellule lance une exécution MLflow dédiée à l'entraînement et à la journalisation d'un modèle LSTM utilisant des embeddings GloVe pré-entraînés.\n",
    "\n",
    "Configuration MLflow : Elle définit un nom pour l'exécution et active l'autologging de TensorFlow/Keras, ce qui permet à MLflow de capturer automatiquement les hyperparamètres, métriques et le modèle lui-même.\n",
    "\n",
    "Paramètres de l'Expérience : Plusieurs paramètres clés liés à l'architecture du modèle (type d'embedding, taille du vocabulaire, longueur de séquence, etc.) et au processus d'entraînement (époques, batch size) sont explicitement loggés dans MLflow.\n",
    "\n",
    "Construction du Modèle : Le modèle LSTM est construit en utilisant la fonction build_lstm_model, en lui passant la matrice d'embeddings GloVe pré-entraînée. Les embeddings sont configurés pour être non entraînables.\n",
    "\n",
    "Entraînement : Le modèle est entraîné sur l'ensemble d'entraînement (X_train_pad, y_train), avec l'ensemble de validation (X_val_pad, y_val) utilisé pour le suivi des performances. Un callback EarlyStopping est mis en place pour arrêter l'entraînement si la précision de validation ne s'améliore pas après un certain nombre d'époques, aidant à prévenir le surapprentissage.\n",
    "\n",
    "Journalisation des Artefacts : Après l'entraînement, le tokenizer Keras (essentiel pour convertir de nouveaux textes en séquences numériques pour la prédiction) est sauvegardé localement puis journalisé en tant qu'artefact MLflow.\n",
    "\n",
    "L'objectif de cette exécution est d'entraîner et d'enregistrer un modèle LSTM performant avec des embeddings GloVe, tout en capturant toutes les métadonnées et artefacts pertinents dans MLflow pour une traçabilité complète et une reproductibilité future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "456ea880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/17 20:10:11 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Démarrage de l'exécution MLflow pour : LSTM_GloVe_Embeddings ---\n",
      "ID de l'exécution MLflow (GloVe) : 62b7b12d38624eb4959f52a64e2d39f4\n",
      "Utilisation de la matrice d'embeddings pré-entraînés.\n",
      "\n",
      "Entraînement du modèle LSTM avec embeddings GloVe...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 93s - 42ms/step - accuracy: 0.7213 - loss: 0.5420 - val_accuracy: 0.7395 - val_loss: 0.5149\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 93s - 42ms/step - accuracy: 0.7404 - loss: 0.5152 - val_accuracy: 0.7474 - val_loss: 0.5028\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 92s - 42ms/step - accuracy: 0.7464 - loss: 0.5056 - val_accuracy: 0.7502 - val_loss: 0.4984\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 92s - 42ms/step - accuracy: 0.7508 - loss: 0.4993 - val_accuracy: 0.7546 - val_loss: 0.4923\n",
      "Epoch 5/10\n",
      "2188/2188 - 92s - 42ms/step - accuracy: 0.7537 - loss: 0.4947 - val_accuracy: 0.7544 - val_loss: 0.4927\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 94s - 43ms/step - accuracy: 0.7564 - loss: 0.4908 - val_accuracy: 0.7570 - val_loss: 0.4892\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 94s - 43ms/step - accuracy: 0.7582 - loss: 0.4877 - val_accuracy: 0.7600 - val_loss: 0.4848\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 95s - 44ms/step - accuracy: 0.7598 - loss: 0.4851 - val_accuracy: 0.7615 - val_loss: 0.4832\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 95s - 43ms/step - accuracy: 0.7613 - loss: 0.4828 - val_accuracy: 0.7625 - val_loss: 0.4820\n",
      "Epoch 10/10\n",
      "2188/2188 - 95s - 43ms/step - accuracy: 0.7628 - loss: 0.4804 - val_accuracy: 0.7618 - val_loss: 0.4824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
      "Entraînement du modèle GloVe terminé.\n",
      "--- Exécution MLflow 62b7b12d38624eb4959f52a64e2d39f4 terminée ---\n"
     ]
    }
   ],
   "source": [
    "# Nom de l'exécution MLflow pour ce modèle spécifique\n",
    "run_name = \"LSTM_GloVe_Embeddings\"\n",
    "\n",
    "print(f\"\\n--- Démarrage de l'exécution MLflow pour : {run_name} ---\")\n",
    "\n",
    "# Activer l'autologging pour TensorFlow/Keras avec MLflow\n",
    "# Cela permet à MLflow de logger automatiquement les paramètres, métriques et modèles\n",
    "mlflow.tensorflow.autolog(\n",
    "    log_models=True,  # Journaliser le modèle entraîné\n",
    "    disable=False,\n",
    "    registered_model_name=None,  # Ne pas enregistrer automatiquement dans le registre de modèles\n",
    ")\n",
    "\n",
    "# Démarrer une nouvelle exécution MLflow\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"ID de l'exécution MLflow (GloVe) : {run_id}\")\n",
    "\n",
    "    # --- Enregistrer les paramètres de l'expérience ---\n",
    "    mlflow.log_param(\"type_embedding\", \"GloVe (Non Entraînable)\")\n",
    "    mlflow.log_param(\"taille_vocabulaire\", actual_vocab_size)\n",
    "    mlflow.log_param(\"longueur_max_sequence\", MAX_SEQUENCE_LENGTH)\n",
    "    mlflow.log_param(\"dimension_embedding\", EMBEDDING_DIM)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"taille_batch\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"architecture\", \"Input-Embedding-LSTM-LSTM-Dense-Dropout-Dense\")\n",
    "\n",
    "    # --- Construire le modèle ---\n",
    "    model_glove = build_lstm_model(\n",
    "        vocab_size=actual_vocab_size,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        max_length=MAX_SEQUENCE_LENGTH,\n",
    "        embedding_matrix=embedding_matrix,  # Utiliser la matrice GloVe\n",
    "        is_embedding_trainable=False,  # Les embeddings GloVe ne sont pas entraînables\n",
    "    )\n",
    "\n",
    "    # --- Callbacks d'entraînement ---\n",
    "    # Arrêt précoce basé sur la précision de validation\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_accuracy\", patience=3, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # --- Entraîner le modèle ---\n",
    "    print(\"\\nEntraînement du modèle LSTM avec embeddings GloVe...\")\n",
    "    history_glove = model_glove.fit(\n",
    "        X_train_pad,\n",
    "        y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=2,  # Afficher les logs d'entraînement par époque\n",
    "    )\n",
    "    print(\"Entraînement du modèle GloVe terminé.\")\n",
    "\n",
    "    # --- Sauvegarder et journaliser le tokenizer ---\n",
    "    # Sauvegarder le tokenizer localement (nécessaire pour recréer l'environnement de prédiction)\n",
    "    with open(\"./advance_exp_1_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "    # Journaliser le tokenizer en tant qu'artefact MLflow\n",
    "    mlflow.log_artifact(\n",
    "        \"advance_exp_1_tokenizer.pkl\", artifact_path=TOKENIZER_ARTIFACT_PATH\n",
    "    )\n",
    "\n",
    "    print(f\"--- Exécution MLflow {run_id} terminée ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd5ee9",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc5_'></a>[Experiment 2: LSTM avec Embeddings Vièrges Entrainable](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55139f86",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc5_1_'></a>[Entrainement du modèle avec MLFlow](#toc0_)\n",
    "\n",
    "Cette cellule est une deuxième exécution MLflow pour l'entraînement d'un modèle LSTM, cette fois-ci avec des embeddings entraînables plutôt que pré-entraînés.\n",
    "\n",
    "Configuration MLflow : Similaire à la cellule précédente, elle définit un nom d'exécution (LSTM_Trainable_Embeddings) et active l'autologging de TensorFlow/Keras.\n",
    "\n",
    "Paramètres de l'Expérience : Les paramètres du modèle et du processus d'entraînement sont loggés, notamment la taille_vocabulaire, longueur_max_sequence, dimension_embedding, etc. Une note d'incohérence est signalée concernant la description de l'architecture par rapport à la fonction build_lstm_model.\n",
    "\n",
    "Construction du Modèle : Le modèle LSTM est construit en appelant build_lstm_model avec embedding_matrix=None et is_embedding_trainable=True. Cela indique à la couche d'embedding d'être initialisée aléatoirement et d'ajuster ses poids pendant l'entraînement.\n",
    "\n",
    "Entraînement : Le modèle est entraîné sur l'ensemble d'entraînement avec validation sur l'ensemble de validation, et utilise également l'EarlyStopping pour éviter le surapprentissage.\n",
    "\n",
    "Journalisation des Artefacts : Le tokenizer Keras est de nouveau sauvegardé localement et journalisé en tant qu'artefact MLflow.\n",
    "\n",
    "L'objectif de cette exécution est d'évaluer les performances du modèle LSTM lorsque les embeddings sont appris directement à partir des données de l'entraînement, et de comparer ces résultats avec ceux obtenus en utilisant des embeddings pré-entraînés (GloVe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f01781e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/17 20:25:53 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Démarrage de l'exécution MLflow pour : LSTM_Trainable_Embeddings ---\n",
      "ID de l'exécution MLflow (Entraînable) : 013e9bc88fe3453e947d3dc74bd6b7e8\n",
      "Utilisation d'une couche d'embeddings entraînables.\n",
      "\n",
      "Entraînement du modèle LSTM avec embeddings entraînables...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 123s - 56ms/step - accuracy: 0.7250 - loss: 0.5379 - val_accuracy: 0.7354 - val_loss: 0.5205\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 116s - 53ms/step - accuracy: 0.7384 - loss: 0.5167 - val_accuracy: 0.7429 - val_loss: 0.5088\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 117s - 53ms/step - accuracy: 0.7436 - loss: 0.5087 - val_accuracy: 0.7463 - val_loss: 0.5037\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 117s - 54ms/step - accuracy: 0.7473 - loss: 0.5033 - val_accuracy: 0.7489 - val_loss: 0.4999\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 116s - 53ms/step - accuracy: 0.7502 - loss: 0.4987 - val_accuracy: 0.7523 - val_loss: 0.4948\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 118s - 54ms/step - accuracy: 0.7530 - loss: 0.4944 - val_accuracy: 0.7549 - val_loss: 0.4922\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 117s - 53ms/step - accuracy: 0.7555 - loss: 0.4907 - val_accuracy: 0.7565 - val_loss: 0.4895\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 118s - 54ms/step - accuracy: 0.7578 - loss: 0.4879 - val_accuracy: 0.7584 - val_loss: 0.4866\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 121s - 55ms/step - accuracy: 0.7592 - loss: 0.4855 - val_accuracy: 0.7596 - val_loss: 0.4849\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 - 120s - 55ms/step - accuracy: 0.7609 - loss: 0.4832 - val_accuracy: 0.7605 - val_loss: 0.4831\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
      "Entraînement du modèle LSTM terminé.\n",
      "--- Exécution MLflow 013e9bc88fe3453e947d3dc74bd6b7e8 terminée ---\n"
     ]
    }
   ],
   "source": [
    "# Chemin d'artefact MLflow pour le tokenizer (redéfini pour clarté, mais la valeur est la même)\n",
    "TOKENIZER_ARTIFACT_PATH = \"tokenizer\"\n",
    "# Chemin d'artefact MLflow pour le modèle (redéfini pour clarté, mais la valeur est la même)\n",
    "MODEL_ARTIFACT_PATH = \"model\"\n",
    "\n",
    "# Nom de l'exécution MLflow pour ce modèle spécifique\n",
    "run_name = \"LSTM_Trainable_Embeddings\"\n",
    "\n",
    "print(f\"\\n--- Démarrage de l'exécution MLflow pour : {run_name} ---\")\n",
    "\n",
    "# Activer l'autologging pour TensorFlow/Keras avec MLflow\n",
    "# Cela permet à MLflow de logger automatiquement les paramètres, métriques et modèles\n",
    "mlflow.tensorflow.autolog(\n",
    "    log_models=True,  # Journaliser le modèle entraîné\n",
    "    disable=False,\n",
    "    registered_model_name=None,  # Ne pas enregistrer automatiquement dans le registre de modèles\n",
    ")\n",
    "\n",
    "# Démarrer une nouvelle exécution MLflow\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"ID de l'exécution MLflow (Entraînable) : {run_id}\")\n",
    "\n",
    "    # --- Enregistrer les paramètres de l'expérience ---\n",
    "    mlflow.log_param(\"vocab_size\", actual_vocab_size)\n",
    "    mlflow.log_param(\"max_sequence_length\", MAX_SEQUENCE_LENGTH)\n",
    "    mlflow.log_param(\"embedding_dim\", EMBEDDING_DIM)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    # Architecture décrite ici est plus simple que celle du build_lstm_model (potentielle incohérence)\n",
    "    mlflow.log_param(\"architecture\", \"Input-Embedding-BiLSTM-Dense\")\n",
    "\n",
    "    # --- Construire le modèle ---\n",
    "    # Ici, embedding_matrix est None et is_embedding_trainable est True, donc l'embedding sera entraîné\n",
    "    model = build_lstm_model(\n",
    "        vocab_size=actual_vocab_size,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        max_length=MAX_SEQUENCE_LENGTH,  # Utiliser MAX_SEQUENCE_LENGTH, pas VOCAB_SIZE\n",
    "        embedding_matrix=None,\n",
    "        is_embedding_trainable=True,\n",
    "    )\n",
    "\n",
    "    # --- Callbacks d'entraînement ---\n",
    "    # Arrêt précoce basé sur la précision de validation\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_accuracy\", patience=3, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # --- Entraîner le modèle ---\n",
    "    print(\"\\nEntraînement du modèle LSTM avec embeddings entraînables...\")\n",
    "    history = model.fit(  # Renommé de history_glove à history pour éviter confusion\n",
    "        X_train_pad,\n",
    "        y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=2,  # Afficher les logs d'entraînement par époque\n",
    "    )\n",
    "    print(\"Entraînement du modèle LSTM terminé.\")\n",
    "\n",
    "    # --- Sauvegarder et journaliser le tokenizer ---\n",
    "    # Sauvegarder le tokenizer localement\n",
    "    with open(\"./advance_exp_2_tokenizer.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "    # Journaliser le tokenizer en tant qu'artefact MLflow\n",
    "    mlflow.log_artifact(\n",
    "        \"advance_exp_2_tokenizer.pkl\", artifact_path=TOKENIZER_ARTIFACT_PATH\n",
    "    )\n",
    "\n",
    "    print(f\"--- Exécution MLflow {run_id} terminée ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408584bf",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc6_'></a>[Evaluation et Selection](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626a633f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc6_1_'></a>[Selection du meilleur modèle (val_accuracy)](#toc0_)\n",
    "\n",
    "Cette cellule utilise le client MLflow pour interroger le serveur de suivi et identifier la meilleure exécution (run) de l'expérience actuelle, basée sur la métrique val_accuracy. Elle récupère l'expérience par son nom, puis effectue une recherche parmi toutes les exécutions, en les filtrant pour n'inclure que celles où val_accuracy est supérieure à 0, et en les triant par ordre décroissant de val_accuracy. Le BEST_RUN_ID est ainsi extrait de l'exécution la mieux classée, et des informations sur celle-ci (comme le type d'embedding utilisé) sont affichées. L'objectif est de sélectionner de manière programmatique le modèle le plus performant pour les étapes d'évaluation et de déploiement ultérieures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f310abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleure exécution sélectionnée automatiquement (basée sur val_accuracy) : 62b7b12d38624eb4959f52a64e2d39f4\n",
      "Type de modèle sélectionné : GloVe (Non Entraînable)\n"
     ]
    }
   ],
   "source": [
    "# Initialiser le client MLflow pour interagir avec le serveur de suivi\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "# Récupérer l'objet de l'expérience MLflow par son nom\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "# Rechercher les exécutions (runs) de cette expérience\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,  # Filtrer par l'ID de l'expérience\n",
    "    filter_string=\"metrics.val_accuracy > 0\",  # Filtrer les exécutions avec une accuracy de validation > 0\n",
    "    order_by=[\n",
    "        \"metrics.val_accuracy DESC\"\n",
    "    ],  # Trier par accuracy de validation décroissante\n",
    "    max_results=1,  # Ne récupérer que la meilleure exécution\n",
    ")\n",
    "# Extraire l'ID de la meilleure exécution\n",
    "BEST_RUN_ID = runs[0].info.run_id\n",
    "print(\n",
    "    f\"Meilleure exécution sélectionnée automatiquement (basée sur val_accuracy) : {BEST_RUN_ID}\"\n",
    ")\n",
    "# Afficher le type d'embedding utilisé dans cette meilleure exécution\n",
    "print(f\"Type de modèle sélectionné : {runs[0].data.params.get('type_embedding')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fbb778",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc6_2_'></a>[Evaluation du modèle sur les données de Test](#toc0_)\n",
    "\n",
    "Cette cellule de code est dédiée à l'évaluation finale du meilleur modèle d'apprentissage automatique identifié précédemment, sur l'ensemble de données de test. Elle commence par charger le modèle sélectionné depuis MLflow, puis calcule et affiche des métriques de performance cruciales telles que la perte, la précision, la précision (precision), le rappel (recall) et le score F1. Un rapport de classification détaillé et une matrice de confusion visuelle sont également générés pour une analyse approfondie des performances. Enfin, toutes ces métriques de test et l'image de la matrice de confusion sont enregistrées en tant qu'artefacts dans l'exécution MLflow correspondante, garantissant ainsi la traçabilité complète des résultats du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2eb05de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Évaluation du Meilleur Modèle (ID de l'exécution : 62b7b12d38624eb4959f52a64e2d39f4) sur l'ensemble de test ---\n",
      "Meilleur modèle chargé avec succès depuis : runs:/62b7b12d38624eb4959f52a64e2d39f4/model\n",
      "\n",
      "Prédiction sur l'ensemble de test...\n",
      "Perte de test : 0.4831\n",
      "Précision de test : 0.7610\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step\n",
      "Précision de test : 0.7454\n",
      "Rappel de test : 0.7927\n",
      "Score F1 de test : 0.7683\n",
      "\n",
      "Rapport de classification (ensemble de test) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75    120000\n",
      "           1       0.75      0.79      0.77    120000\n",
      "\n",
      "    accuracy                           0.76    240000\n",
      "   macro avg       0.76      0.76      0.76    240000\n",
      "weighted avg       0.76      0.76      0.76    240000\n",
      "\n",
      "\n",
      "Matrice de confusion (ensemble de test) :\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métriques de test enregistrées dans l'exécution MLflow sélectionnée.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\n",
    "    f\"\\n--- Évaluation du Meilleur Modèle (ID de l'exécution : {BEST_RUN_ID}) sur l'ensemble de test ---\"\n",
    ")\n",
    "\n",
    "# Chargement du meilleur modèle depuis MLflow\n",
    "model_uri = f\"runs:/{BEST_RUN_ID}/{MODEL_ARTIFACT_PATH}\"\n",
    "loaded_model = mlflow.tensorflow.load_model(model_uri)\n",
    "print(f\"Meilleur modèle chargé avec succès depuis : {model_uri}\")\n",
    "\n",
    "print(\"\\nPrédiction sur l'ensemble de test...\")\n",
    "# Évaluation du modèle sur l'ensemble de test pour obtenir la perte et la précision\n",
    "loss, accuracy = loaded_model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "print(f\"Perte de test : {loss:.4f}\")\n",
    "print(f\"Précision de test : {accuracy:.4f}\")\n",
    "\n",
    "# Prédiction des probabilités et conversion en classes binaires (0 ou 1)\n",
    "y_pred_proba = loaded_model.predict(X_test_pad)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calcul des métriques de classification (précision, rappel, F1-score)\n",
    "test_precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "test_recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "test_f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Précision de test : {test_precision:.4f}\")\n",
    "print(f\"Rappel de test : {test_recall:.4f}\")\n",
    "print(f\"Score F1 de test : {test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nRapport de classification (ensemble de test) :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nMatrice de confusion (ensemble de test) :\")\n",
    "# Calcul et affichage de la matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Non-Négatif\", \"Négatif\"],\n",
    "    yticklabels=[\"Non-Négatif\", \"Négatif\"],\n",
    ")\n",
    "plt.xlabel(\"Étiquette Prédite\")\n",
    "plt.ylabel(\"Étiquette Réelle\")\n",
    "plt.title(\"Matrice de Confusion (Ensemble de Test)\")\n",
    "plt.show()\n",
    "\n",
    "# Enregistrement des métriques de test dans l'exécution MLflow\n",
    "client.log_metric(BEST_RUN_ID, \"test_loss\", loss)\n",
    "client.log_metric(BEST_RUN_ID, \"test_accuracy\", accuracy)\n",
    "client.log_metric(BEST_RUN_ID, \"test_precision\", test_precision)\n",
    "client.log_metric(BEST_RUN_ID, \"test_recall\", test_recall)\n",
    "client.log_metric(BEST_RUN_ID, \"test_f1\", test_f1)\n",
    "print(\"\\nMétriques de test enregistrées dans l'exécution MLflow sélectionnée.\")\n",
    "\n",
    "# Sauvegarde et enregistrement de la matrice de confusion en tant qu'artefact MLflow\n",
    "fig_path = \"test_confusion_matrix.png\"\n",
    "plt.savefig(fig_path)\n",
    "client.log_artifact(BEST_RUN_ID, fig_path)\n",
    "# Suppression du fichier local de la figure après l'enregistrement\n",
    "if os.path.exists(fig_path):\n",
    "    os.remove(fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd1e419",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc6_3_'></a>[Enregistrement du model](#toc0_)\n",
    "\n",
    "Cette cellule de code a pour objectif d'enregistrer le meilleur modèle entraîné dans le registre de modèles de MLflow sous le nom \"MODEL_ADVANCED\". L'enregistrement permet de versionner le modèle, de le suivre et de gérer son cycle de vie (par exemple, le déploiement en production). Une fois enregistré, les informations clés telles que le nom, la version et le stage actuel du modèle sont affichées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40513157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle enregistré avec succès :\n",
      "- Nom : MODEL_ADVANCED\n",
      "- Version : 3\n",
      "- Stage : None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'MODEL_ADVANCED' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'MODEL_ADVANCED'.\n"
     ]
    }
   ],
   "source": [
    "# Enregistrement du modèle dans le registre de modèles MLflow\n",
    "# L'URI pointe vers l'artefact \"model\" de la meilleure exécution\n",
    "registered_model_info = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{BEST_RUN_ID}/model\", name=\"MODEL_ADVANCED\"\n",
    ")\n",
    "print(\"Modèle enregistré avec succès :\")\n",
    "print(f\"- Nom : {registered_model_info.name}\")\n",
    "print(f\"- Version : {registered_model_info.version}\")\n",
    "print(f\"- Stage : {registered_model_info.current_stage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c9a28",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <a id='toc7_'></a>[Dashboard MLFlow](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09c7928b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8350fe3b",
   "metadata": {},
   "source": [
    "![Overview](./mlflow_screenshot/advanced/Overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb79a3f",
   "metadata": {},
   "source": [
    "![Metrics](./mlflow_screenshot/advanced/Metrics.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
